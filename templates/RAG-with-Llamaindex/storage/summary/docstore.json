{"docstore/data": {"635f3021-82ee-42ed-a18a-b87275b255cd": {"__data__": {"id_": "635f3021-82ee-42ed-a18a-b87275b255cd", "embedding": null, "metadata": {"page_label": "1", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c59b5c7f-8102-4ae2-ba20-052bf99eb4e1", "node_type": "4", "metadata": {"page_label": "1", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "e6148c00259359ab65ee04ec09b84d7253269ee9677017349019e906daec3dc1", "class_name": "RelatedNodeInfo"}}, "text": "QUERY 2CAD: G ENERATING CAD MODELS USING NATURAL\nLANGUAGE QUERIES\nAkshay Badagabettu\nMechanical Engineering\nCarnegie Mellon University\nPittsburgh, PA 15213\nabadagab@andrew.cmu.eduSai Sravan Yarlagadda\nMechanical Engineering\nCarnegie Mellon University\nPittsburgh, PA 15213\nsaisravy@andrew.cmu.eduAmir Barati Farimani\nMechanical Engineering\nCarnegie Mellon University\nPittsburgh, PA 15213\nbarati@cmu.edu\nJune 5, 2024\nABSTRACT\nComputer Aided Design (CAD) engineers typically do not achieve their best prototypes in a single\nattempt. Instead, they iterate and refine their designs to achieve an optimal solution through multiple\nrevisions. This traditional approach, though effective, is time-consuming and relies heavily on the\nexpertise of skilled engineers. To address these challenges, we introduce Query2CAD, a novel\nframework to generate CAD designs. The framework uses a large language model to generate\nexecutable CAD macros. Additionally, Query2CAD refines the generation of the CAD model with\nthe help of its self-refinement loops. Query2CAD operates without supervised data or additional\ntraining, using the LLM as both a generator and a refiner. The refiner leverages feedback generated by\nthe BLIP2 model, and to address false negatives, we have incorporated human-in-the-loop feedback\ninto our system. Additionally, we have developed a dataset that encompasses most operations used\nin CAD model designing and have evaluated our framework using this dataset. Our findings reveal\nthat when we used GPT-4 Turbo as our language model, the architecture achieved a success rate of\n53.6% on the first attempt. With subsequent refinements, the success rate increased by 23.1%. In\nparticular, the most significant improvement in the success rate was observed with the first iteration\nof the refinement. With subsequent refinements, the accuracy of the correct designs did not improve\nsignificantly. We have open-sourced our data, model, and code.1\n1 Introduction\nCAD has revolutionized the way engineers, architects, and designers conceptualize and design prototypes and products.\nCAD designing is a very important step to design prototypes and also it helps in understanding the potential failures that\nmight occur during the manufacturing phase. Over the years, CAD softwares have evolved significantly and become\nvery powerful. CAD designing was always done by a CAD engineer as it required a deep understanding of complex\noperations [ 1]. The reasoning capabilities of LLMs have simplified many complex problems [ 2]. However, using LLMs\nto aid in the generation of CAD models remains largely untapped. The integration of natural language processing into\nCAD can significantly improve the design time. It can also make complex CAD software more accessible to people\nwith less experience in CAD designing.\nOver the past decade, deep learning methods had significant success in understanding data formats like mesh\n[3], voxels [ 4], and point clouds. With the advent of diffusion models, a significant shift occurred towards\nimage-conditioned 3D generative modeling, particularly enhancing the capabilities in point clouds and neural fields\n[5]. A critical limitation identified in these studies was the necessity for precise camera poses, which constrained the\napplicability and flexibility of the models. Recent innovations eliminated the need for camera poses [ 6], but the major\ndrawback of such data format is the problems that it might pose during feature extraction. These extracted features are\n1github.com/akshay140601/Query2CADarXiv:2406.00144v1  [cs.LG]  31 May 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3580, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2dece173-f18e-4234-82b6-e8e8d3b461aa": {"__data__": {"id_": "2dece173-f18e-4234-82b6-e8e8d3b461aa", "embedding": null, "metadata": {"page_label": "2", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "773a6811-e18b-4a58-8a0b-1a1c4e789b0c", "node_type": "4", "metadata": {"page_label": "2", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "77106ae1c84d158af75ebb182ff0beee7de5f0a76e5b8b333c4ffda617254e42", "class_name": "RelatedNodeInfo"}}, "text": "Figure 1: Proposed architecture of Query2CAD. The user query is passed to an LLM that generates a Python macro to\ngenerate the corresponding CAD model. The isometric view is captured, and refinement is performed if the VQA score\ndoes not cross the threshold. The loop is run for a maximum of 3 times.\ncritical to the CAD model, and converting them to the right data format, such as triangular meshes, can be expensive\nand can also lead to information loss [7].\nIn this work, we introduce Query2CAD, a novel architecture that returns a CAD model similar to the user\u2019s\nprompt. We plan to exploit the capabilities of language models to generate Python programs (Macro) that can be\nexecuted in the FreeCAD software to obtain 3D CAD models. A designer refines his design multiple times based\non the feedback given to him until he designs a CAD model that closely aligns with what the user has asked for. To\nmimic this behavior, our architecture has a refinement loop that refines its generation with respect to the user prompt.\nWe incorporated a caption-generating model to provide feedback on what was designed, and, to encounter the false\nnegatives of this model, we have also incorporated human-in-the-loop feedback. We have used Visual Question\nAnswering Score [ 8] to check if we have reached an optimal CAD design. At a high level, our architecture takes input\nfrom the user (for instance, \"Give me the CAD design of a water bottle\") and passes it to a language model, which\ngenerates a working CAD design. Throughout this process, users do not require any prior knowledge of CAD software\nand can interact with the system using natural language. A brief overview of our architecture is shown in Figure 1.\n2 Related works\nGenerating 3D models: Early explorations of generating 3D models used variational autoencoders [ 9] [10]. However,\nthis just worked for simple models, and the 3D models generated were very similar to that of the training corpus and\nfailed at generating models outside of the training corpus [ 11]. Later researchers have investigated 3D GANs [ 12] [13],\nbut the main drawback of generating 3D models using GAN is its instability during training [ 14]. However, recently\nimage conditioned 3D modeling has shown good results in generating 3D models[ 15] but the precision is not very good\nwhen compared to that of a CAD model. In our research, we aim to advance beyond point cloud generation to focus on\n3D CAD model creation. CAD models are pivotal to the manufacturing process and facilitate the direct transfer of\ndata to production machinery. While 3D models generated by various image-to-3D diffusion models have accurately\ncaptured the geometry of points in the 3D CAD models [ 16], CAD models provide more profound utility by enabling\nan advanced level of design, analysis, and manufacturability.\nInnovative approaches taken by people that can assist in 3D CAD model generation: Recent studies,\nsuch as those by [ 17], have highlighted the capability of language models in generating conceptual designs. These\nstudies demonstrate that language models can effectively reason and produce detailed concept designs that can\nsignificantly assist design engineers in their work. Some works [ 18] integrated imagery of the model into their 3D CAD\ndesign software, enhancing the design process by inspiring more innovative ideas among designers as they create their\nmodels. However, our research aims to directly generate 3D CAD models based on prompts provided by users.\nSelf-refinement Loops: The iterative process used in human problem-solving, such as in CAD design, typi-\ncally involves creating an initial model and refining it based on identified flaws, a method rooted in broader\n2", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3708, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d5cfbf8e-0bc6-4496-ad60-3ba587d4f9dc": {"__data__": {"id_": "d5cfbf8e-0bc6-4496-ad60-3ba587d4f9dc", "embedding": null, "metadata": {"page_label": "3", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cf2cad0-b01b-442c-a355-b4910b3cc475", "node_type": "4", "metadata": {"page_label": "3", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "52899ada24b7788deaf53d80bbc840197445af5ea778c5445ca9d34522c6f5c8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9d65d48-6f13-42ef-a5b6-6c4305fe24e7", "node_type": "1", "metadata": {}, "hash": "b10e268289fd36282840171b4af99369e3efca52a105a32b0ef8e3b51b65f848", "class_name": "RelatedNodeInfo"}}, "text": "problem-solving strategies discussed by [ 19]. Unlike this human approach, most current language models generate\noutputs in a single step, which contrasts with the iterative nature of human task performance [ 20], [21]. Although\nsome research, such as [ 22], has explored post-inference editing, these methods typically do not support multi-step\nrefinement. Recent advancements include the development of models that integrate iterative feedback mechanisms to\nenhance output quality [ 23]. This model iteratively refines its output by reprocessing its initial output through the\nmodel to obtain and incorporate feedback internally. We aim to incorporate this approach into our architecture, thereby\nemulating the way CAD designers iteratively refine their prototypes.\nHuman evaluation has been the gold standard in many evaluation tasks. [ 24], [25] integrated human feed-\nback during generation steps to directly address errors made by the models during generation. Inspired by such\napproaches, we see strong capabilities in achieving optimal generation results. Thus, we have incorporated it into every\nloop of our Query2CAD architecture.\n3 Preliminaries\nIn this section, we have discussed more about some important components used in various modules of Query2CAD.\nAdvancements in Large Language Models for Code Generation: Recent advances in language modeling\nhave been propelled by the introduction of pre-trained Transformer models [ 2], such as BERT [ 26] and GPT [ 27].\nLLMs like ChatGPT [ 28] have demonstrated exceptional capabilities in code generation. This progress has given rise to\nspecialized LLMs focused on software engineering, known as Code LLMs. Typically, these Code LLMs evolve from\ngeneral-purpose LLMs through a process of fine-tuning, with their effectiveness being dependent on the foundational\nLLMs.\nNotably, models such as GPT-3.5 Turbo, GPT-4 Turbo and CodeLLAMA have exhibited advanced capabili-\nties in this area. GPT-3.5 Turbo, refined through advanced training techniques like Reinforcement Learning from\nHuman Feedback (RLHF) [ 29], excels in producing precise and contextually relevant code outputs. This is critical in\nenvironments where integration with existing systems or adherence to specific programming standards is important.\nThe model\u2019s ability to understand and process user instructions in natural language and convert them into functional\ncode has made it a valuable tool in domains requiring high accuracy and detailed command execution. In benchmark\ntests like HumanEval, GPT-4 Turbo and CodeLLAMA have shown superior performance in code generation tasks [ 30].\nBy incorporating these LLMs, our system can facilitate more dynamic and interactive design processes, effectively\nreducing the time and expertise required to execute complex CAD design tasks.\nStopping criteria: We have used Visual Question Answering Score (VQAScore) [ 8] as our stopping criteria.\nVQA systems have significantly advanced the integration of textual and visual data, providing a robust framework for\nevaluating the alignment between text descriptions and generated images. These systems utilize multimodal LLMs that\neffectively combine and process both modalities, enhancing the ability to accurately interpret and respond to complex\nqueries about visual content. The core functionality of VQA involves transforming text descriptions into specific\nquestions, typically formatted to elicit yes-or-no answers, which are then processed alongside images. This interaction\nis mediated by bidirectional encoders, allowing the textual and visual inputs to dynamically influence each other\u2019s\nprocessing within the model. The resulting output is a probability distribution over potential answers, with a focus on\nthe likelihood of \"Yes,\" indicating a strong alignment between the image and its textual description. The VQAScore,\nderived from this probability, quantifies the degree of text-image congruence, offering a direct measure of the quality\nand relevance of the visual output in relation to the text prompt. Equation 1 gives the mathematical representation of the\nVQAScore.\nP(\"Yes\"|image ,\u2032\u2032Does this figure show {user _query}?Please answer yes or no.\u2032\u2032) (1)\nCaption Models in Computational Design: BLIP2 (Bootstrapped Language-Image Pre-training 2) [ 31] is a caption\nmodel with a dual encoder-decoder architecture. This architecture effectively processes visual and textual inputs\nsimultaneously, enabling BLIP2 to generate detailed and contextually accurate captions. BLIP2 employs transformers\nfor handling complex data sequences and utilizes contrastive learning to align textual and visual representations closely,\nwhich improves its caption relevance and accuracy over other models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4714, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d9d65d48-6f13-42ef-a5b6-6c4305fe24e7": {"__data__": {"id_": "d9d65d48-6f13-42ef-a5b6-6c4305fe24e7", "embedding": null, "metadata": {"page_label": "3", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cf2cad0-b01b-442c-a355-b4910b3cc475", "node_type": "4", "metadata": {"page_label": "3", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "52899ada24b7788deaf53d80bbc840197445af5ea778c5445ca9d34522c6f5c8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d5cfbf8e-0bc6-4496-ad60-3ba587d4f9dc", "node_type": "1", "metadata": {"page_label": "3", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "3545ca8428e11e25cac3145bedcf7e3dde6ea1e2ed6d3811edff740ced22b9c5", "class_name": "RelatedNodeInfo"}}, "text": "The VQAScore,\nderived from this probability, quantifies the degree of text-image congruence, offering a direct measure of the quality\nand relevance of the visual output in relation to the text prompt. Equation 1 gives the mathematical representation of the\nVQAScore.\nP(\"Yes\"|image ,\u2032\u2032Does this figure show {user _query}?Please answer yes or no.\u2032\u2032) (1)\nCaption Models in Computational Design: BLIP2 (Bootstrapped Language-Image Pre-training 2) [ 31] is a caption\nmodel with a dual encoder-decoder architecture. This architecture effectively processes visual and textual inputs\nsimultaneously, enabling BLIP2 to generate detailed and contextually accurate captions. BLIP2 employs transformers\nfor handling complex data sequences and utilizes contrastive learning to align textual and visual representations closely,\nwhich improves its caption relevance and accuracy over other models.\nThe model\u2019s superior performance is also due to its extensive pre-training on diverse datasets, allowing it to understand\nvarious visual contexts and descriptions comprehensively. BLIP2 generates captions by encoding images and texts,\nmerging these into a joint representation, and then decoding this representation into precise captions. This capability\n3", "mimetype": "text/plain", "start_char_idx": 3832, "end_char_idx": 5071, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cde0aecb-346b-4949-9e50-1984abd456a0": {"__data__": {"id_": "cde0aecb-346b-4949-9e50-1984abd456a0", "embedding": null, "metadata": {"page_label": "4", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a897750-61b1-49fb-a62d-e2485fffb8d6", "node_type": "4", "metadata": {"page_label": "4", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "5d6fc43f9c118e4f6fc17f068bd29023cd7f7700810b31bb00fd05d937a6c0bb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "655fc578-1694-4e4a-b349-c9c3eb3904bc", "node_type": "1", "metadata": {}, "hash": "97767ad91c31070d948eb63006b17024e8ab621f7b9c572ec05373c1ad99e0a8", "class_name": "RelatedNodeInfo"}}, "text": "makes BLIP2 particularly valuable in design environments, facilitating automated documentation and insightful\nfeedback during the design process.\n4 Methodology\nWe propose Query2CAD: A novel framework to generate 3-dimensional CAD models using only natural language\ninstructions/queries. The proposed architecture is shown in Figure 1. The individual components of the architecture\nhave been explained in the previous section. We now delve deeper into how our proposed system works as a whole.\nThe user query is passed into a strong LLM (we have tested out our architecture using GPT-3.5 turbo and\nGPT-4 turbo). The LLM first generates the steps required to make the model in natural language. Using these steps\nit then generates a Python macro that can be executed on the FreeCAD software. FreeCAD [ 32] is an open-source\nCAD modeling software. If there is any error encountered when running the macro, the first type of refinement,\nviz., error refinement, is performed. The error message and the Python code are passed to the LLM to rectify the er-\nror and get an executable code. The error refinement is done for a user-defined error _iter number of times (default is 3).\nOnce an executable code is obtained, the macro is executed on the FreeCAD software, and the isometric\nview of the CAD model is captured. The similarity or VQAScore between the user query and the generated isometric\nimage is calculated by using Clip-FlanT5-XL as the VQA model. If the VQA score exceeds a user-defined threshold\n(default is 0.9), then the process stops, and the generated model is the final CAD design for the specified user query.\nBut, if the threshold is not crossed, the second type of refinement, viz., model refinement, is performed. The previously\ncaptured isometric view of the CAD model is given a caption either by strong caption-generating models such as BLIP2\nor by the user. The caption essentially encompasses what the LLM generated. This caption is passed as feedback to the\nLLM along with the generated Python code and the user query. The LLM finds the difference between the feedback and\nthe user query and generates a modified version of its code, trying to correct its mistake. This self-refinement continues\nuntil the VQA score crosses the threshold or the user-defined number of model refinement iterations is reached (default\nis 3). Currently, evaluation is done manually by checking the generated 3D model and its corresponding prompt. The\nentire process of navigating the FreeCAD software, i.e., opening macro, executing the code, capturing screenshots, and\nclosing the software, has been automated using PyAutoGUI [ 33], which is a very useful Python library that can control\nthe keyboard and mouse. Few-shot prompting was done when writing all the prompts whenever the LLM was called.\nThe prompts can be seen in link\n5 Experiments and Results\n5.1 Dataset\nAs there is no dataset for this particular task, we created an experimental dataset composed of questions with varying\nlevels of difficulty, segmented into easy, medium, and hard categories. The easy section includes straightforward shapes\nlike cubes or spheres. For instance, a typical question might be, \"A CAD design of a cube with a side length of 10mm.\"\nMedium-difficulty questions involve basic shapes coupled with elementary operations, such as \"A cube with a side\nlength of 10mm positioned atop a sphere with an 8mm radius.\" For such inquiries, the LLM must not only generate\nthe respective shapes but also discern their spatial arrangement. The hard category tackles more intricate designs and\noperations. An example of a challenging question is, \"A CAD design of a basketball hoop.\" These questions demand\nthat the LLMs model complex structures and comprehend the positioning of each component within the design. Our\ncurated dataset comprises approximately 21 easy questions, 20 medium questions, and 16 hard questions. Totally, in\nour curated dataset, we have 57 user queries.\n5.2 Results\nQuery2CAD achieved great performance on easy-level questions, achieving an impressive accuracy of 95.23% using\nGPT-4 Turbo as the LLM. Additionally, the model maintained commendable accuracy levels for medium and hard\nquestions, at 70% and 41%, respectively. We have strategically selected GPT-4 as our language model, serving dual\nroles as both generator and refiner.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "655fc578-1694-4e4a-b349-c9c3eb3904bc": {"__data__": {"id_": "655fc578-1694-4e4a-b349-c9c3eb3904bc", "embedding": null, "metadata": {"page_label": "4", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9a897750-61b1-49fb-a62d-e2485fffb8d6", "node_type": "4", "metadata": {"page_label": "4", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "5d6fc43f9c118e4f6fc17f068bd29023cd7f7700810b31bb00fd05d937a6c0bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cde0aecb-346b-4949-9e50-1984abd456a0", "node_type": "1", "metadata": {"page_label": "4", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "8fd57aa977a25032b0dda66e41afd2607bf9d1c95cba02e8336aaaf0c7ef4e37", "class_name": "RelatedNodeInfo"}}, "text": "The hard category tackles more intricate designs and\noperations. An example of a challenging question is, \"A CAD design of a basketball hoop.\" These questions demand\nthat the LLMs model complex structures and comprehend the positioning of each component within the design. Our\ncurated dataset comprises approximately 21 easy questions, 20 medium questions, and 16 hard questions. Totally, in\nour curated dataset, we have 57 user queries.\n5.2 Results\nQuery2CAD achieved great performance on easy-level questions, achieving an impressive accuracy of 95.23% using\nGPT-4 Turbo as the LLM. Additionally, the model maintained commendable accuracy levels for medium and hard\nquestions, at 70% and 41%, respectively. We have strategically selected GPT-4 as our language model, serving dual\nroles as both generator and refiner. When we used GPT-3.5-Turbo as our language model we observed that the accuracy\non easy questions was 85.71% and that of medium and hard was 35% and 37.5% respectively. We define an output as\ncorrect only if it produces the exact 3D CAD model as specified by the user. Any deviation from the specified design, no\nmatter how minor, is considered a failure. Table 1 displays the success rates achieved by Query2CAD when evaluated\nacross the dataset described in Section 5.1. It also shows the success rates across various user queries with varied\ndifficulty levels. Table 2 shows the improvements shown by Query2CAD across various refinement loops. Figures 3\n4", "mimetype": "text/plain", "start_char_idx": 3519, "end_char_idx": 4995, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cf22d3f4-0052-4924-af01-cfdd9dac0921": {"__data__": {"id_": "cf22d3f4-0052-4924-af01-cfdd9dac0921", "embedding": null, "metadata": {"page_label": "5", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7538d4cc-633e-4cd6-a6c4-c4fb6f5c1f10", "node_type": "4", "metadata": {"page_label": "5", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "2ba8478cccd583ea71b2fe438002841878f4f804e0107ea47a69d9eb9735a154", "class_name": "RelatedNodeInfo"}}, "text": "and 2 illustrate two outputs generated by Query2CAD, including any necessary refinements to the CAD model and the\ncorresponding feedback provided to the model.\nFigure 2: The user query was to make a book shelf and a torus respectively. The book shelf was designed correctly\nwithin 1 refinement whereas the torus was designed correctly in the first attempt (direct generation)\nFigure 3: The user query was to make a plate in the shape of a star. The LLM first generated a code that made a\npentagon shape. The feedback given was to close that shape. It then made a closed pentagon with some thickness. The\nsecond feedback given was to alter the shape to a star. A star-shaped plate was then obtained\nDifficulty level\nModel Easy Medium Hard\nGPT-3.5 Turbo 85.71% 35% 37.5%\nGPT-4 Turbo 95.23% 70% 41.7%\nTable 1: Query2CAD results on generating correct 3D\nCAD models using GPT-3.5 as both, base and the refiner.\nMetrics used for this task are defined in SectionModel y0 y1 y2 y3\nGPT-3.5 Turbo 32.7% 44.8% 51.7% 53.4%\nGPT-4 Turbo 53.6% 73.2% 76.7% 76.7%\nTable 2: y0refers to the success rate of Query2CAD\nwhen the user query is passed directly to the LLM, and\ny1,y2, and y3refer to the success rate of Query2CAD\nafter the first, second, and third refinements, respectively.\n6 Analysis\nIn the following section, we analyzed some results generated by the architecture in finer detail and the importance of\neach module in our architecture.\nHow important are the multiple model refinement iterations? Table 2 shows the accuracy of the system for the\ninitial output i.e., direct generation ( y0), and the three refinement iterations ( y1,y2,y3). We see that, on average,\nthe accuracy improves as the number of model refinement iterations increases. But, we also notice only marginal\nimprovements after the first refinement. This shows the importance of the first refinement, and the trend we see here\nwas the same trend seen in [ 20], albeit for different tasks. However, for a few test cases with GPT-4 as the base\nmodel, it was seen that each model refinement iteration significantly improved the 3D model, but, the number of\nrefinement iterations was not enough to generate the exact model. Figure 4 shows the improvement in success rates after\neach iteration shown by both GPT-4 turbo and GPT-3.5 turbo. This plot clearly shows the importance of the first iteration.\nPerformance of the system on various difficulty levels of the query: Table 1 shows the accuracy of the\nsystem on easy, medium, and hard levels of user queries. Refer to Section 5.1 for more information on the dataset. We\nsee that the system performs very well on the easy questions, but there is a stark decrease in performance when it comes\nto the medium and hard queries especially when using GPT-3.5 turbo as the base model. This trend is expected, and\nperformance can be improved by finetuning the LLM on FreeCAD macros. When using a stronger model (GPT-4\nturbo), we see a huge increase in the success rate for both the easy and medium queries.\n5", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3009, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "159bfe09-056d-411f-ad92-7b4c2f0b4a3d": {"__data__": {"id_": "159bfe09-056d-411f-ad92-7b4c2f0b4a3d", "embedding": null, "metadata": {"page_label": "6", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b67424d1-ad15-4e02-bc19-0e403c097e5e", "node_type": "4", "metadata": {"page_label": "6", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "a720cd2392a933848ab25d6987c761206ad145aae7142e9804b78036669fbf54", "class_name": "RelatedNodeInfo"}}, "text": "Figure 4: The bar chart shows the observed improve-\nment in success rate after every iteration. \u2206(y0\u2192y1)\nrefers to the improvement in success rate from direct\ngeneration to first iteration. Similarly \u2206(y1\u2192y2)\nand\u2206(y2\u2192y3)refers to the improvement in success\nrates in subsequent iterations. All the values are in\npercentages.\nFigure 5: 69% of the 13 failed cases when using\nGPT-4-turbo as the LLM was due to not getting an\nexecutable code and the remaining 31% of failures\nwere due to generating the wrong structure. Similarly,\nwhen using GPT 3.5-turbo as the LLM, 65.4% of\nfailures were due to not getting an executable code and\n34.6% of failures were due to generating the wrong\nstructure\nPerformance of the system with weaker models: The results shown in Table 1 and Table 2 are results of\nexperiments performed using two of the strongest models available. Codellama-70b [ 34] was used as the base model to\ncheck the impact on the performance when using a weaker model. We observed extremely bad generated outputs by\nusing a weaker model. Codellama was not able to perform reasoning very well, and sometimes, it even failed to give\nconsistent responses to the same query. We also noticed a lot of hallucinations [35].\nWhat were the reasons behind the failed cases? Figure 5 shows the two kinds of failures that were ob-\nserved. When using GPT-3.5 turbo as the base model, there were a total of 26 failed cases out of 57 data points, and\n65.4% of the failed cases were because of not getting an executable code even after doing error refinements. The\nremaining 34.6% of the failed cases were because the model did not generate the correct structure (user query and\ngenerated output did not match even after the model refinements). The same trend can be seen when using GPT-4 turbo\nas the base model although there were only 13 errors. This shows that most of the errors are due to not getting an\nexecutable code and there can be some potential improvement in the way we perform error refinements.\nWas the BLIP2 caption model effective? During the experiments, we performed human-in-the-loop feed-\nback wherein the BLIP2 model generates the caption first, and the user can intervene and provide their own caption if\nnecessary. We noticed that the model was not able to refine very well with the caption generated only with BLIP2.\nEven though most of the time, the BLIP2 caption was perfect, we observed that providing what the generated model\nlooks like and the steps to correct it made refinement much better. Currently, providing human feedback is much better,\nbut it makes the system less autonomous.\n7 Limitations and future work\nOne major limitation of our system is that it works very well only with strong models that are not open-source at this\npoint of time. This is because, in our system, the LLM must be capable of both complex code generation and reasoning.\nCurrently, our curated dataset has only 57 queries. Even though we have queries of all the difficulty levels, increasing\nthe size of the dataset can provide more insight into the actual performance of the system.\nHuman feedback works much better than any caption-generating model. The performance of the system is much better\nif we give the LLM what it generated and what it should do to correct itself. While this works great, the system becomes\nless autonomous. A promising future direction is to also input the user query in text format and either a corresponding\nsketch or image of the query.\n6", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3468, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5d5bb538-1a0e-419b-9d06-6ad736ffe6e5": {"__data__": {"id_": "5d5bb538-1a0e-419b-9d06-6ad736ffe6e5", "embedding": null, "metadata": {"page_label": "7", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3d9084ea-893c-4ce6-9fbf-025fbdb71a48", "node_type": "4", "metadata": {"page_label": "7", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "c3c8eeb2e23ea974e1a2b7c3b04394c9c060bd509a4e31a5a6327ba8a66f00dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ecc5733-79d9-453a-8f74-f440e5d9a774", "node_type": "1", "metadata": {}, "hash": "b9234b1b8214134dc1f5b15d4483b0fca6fc2ce2d95dac0202dfb28b0a263a3f", "class_name": "RelatedNodeInfo"}}, "text": "8 Conclusion\nWe introduce Query2CAD, a novel approach for generating 3D CAD models. Query2CAD addresses this challenge by\ncreating a macro that, when executed, produces a 3D CAD model. This model employs an iterative process through its\narchitecture to ensure precise output generation. It also includes a feedback loop that employs either a BLIP2 model\nto describe the resemblance of the previous 3D output or direct human input to make changes to the previous design\ngenerated. We have curated a dataset comprised of diverse user queries. Upon testing these queries with Query2CAD,\nwe found that our model excels at generating 3D models of simple shapes with an impressive accuracy rate of 95.23%.\nFor medium and hard-level queries, the model maintains a success rate of 70% and 41% respectively. Notably, our\nmodel demonstrates a significant improvement in success rate during its initial refinement phase. To this end, we make\nall our code, data, and prompts available at link.\nReferences\n[1]David J Kasik, William Buxton, and David R Ferguson. Ten cad challenges. IEEE Computer Graphics and\nApplications , 25(2):81\u201392, 2005.\n[2]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and\nIllia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017.\n[3]Evangelos Kalogerakis, Melinos Averkiou, Subhransu Maji, and Siddhartha Chaudhuri. 3d shape segmentation\nwith projective convolutional networks. In proceedings of the IEEE conference on computer vision and pattern\nrecognition , pages 3779\u20133788, 2017.\n[4]Yutong Feng, Yifan Feng, Haoxuan You, Xibin Zhao, and Yue Gao. Meshnet: Mesh neural network for 3d shape\nrepresentation. In Proceedings of the AAAI conference on artificial intelligence , volume 33, pages 8279\u20138286,\n2019.\n[5]Luke Melas-Kyriazi, Christian Rupprecht, and Andrea Vedaldi. Pc2: Projection-conditioned point cloud diffusion\nfor single-image 3d reconstruction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition , pages 12923\u201312932, 2023.\n[6]Jiale Xu, Weihao Cheng, Yiming Gao, Xintao Wang, Shenghua Gao, and Ying Shan. Instantmesh: Effi-\ncient 3d mesh generation from a single image with sparse-view large reconstruction models. arXiv preprint\narXiv:2404.07191 , 2024.\n[7] J Chen, OE Mora, and KC Clarke. Assessing the accuracy and precision of imperfect point clouds for 3d indoor\nmapping and modeling. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences ,\n4:3\u201310, 2018.\n[8]Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, Graham Neubig, Pengchuan Zhang, and Deva Ramanan.\nEvaluating text-to-visual generation with image-to-text generation. arXiv preprint arXiv:2404.01291 , 2024.\n[9]Paul Henderson, Vagia Tsiminaki, and Christoph H Lampert. Leveraging 2d data to learn textured 3d mesh\ngeneration. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages\n7498\u20137507, 2020.\n[10] Paul Henderson and Vittorio Ferrari. Learning single-image 3d reconstruction by generative modelling of shape,\npose and shading. International Journal of Computer Vision , 128(4):835\u2013854, 2020.\n[11] L Mi, M Shen, and J Zhang. A probe towards understanding gan and vae models. arxiv 2018. arXiv preprint\narXiv:1812.05676 .\n[12] Thu H Nguyen-Phuoc, Christian Richardt, Long Mai, Yongliang Yang, and Niloy Mitra.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3415, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3ecc5733-79d9-453a-8f74-f440e5d9a774": {"__data__": {"id_": "3ecc5733-79d9-453a-8f74-f440e5d9a774", "embedding": null, "metadata": {"page_label": "7", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3d9084ea-893c-4ce6-9fbf-025fbdb71a48", "node_type": "4", "metadata": {"page_label": "7", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "c3c8eeb2e23ea974e1a2b7c3b04394c9c060bd509a4e31a5a6327ba8a66f00dd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5d5bb538-1a0e-419b-9d06-6ad736ffe6e5", "node_type": "1", "metadata": {"page_label": "7", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "8495741c4bfc50d5e2532c11db62ab093aa68ba9c04fea2406b0afadee1ea010", "class_name": "RelatedNodeInfo"}}, "text": "[9]Paul Henderson, Vagia Tsiminaki, and Christoph H Lampert. Leveraging 2d data to learn textured 3d mesh\ngeneration. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages\n7498\u20137507, 2020.\n[10] Paul Henderson and Vittorio Ferrari. Learning single-image 3d reconstruction by generative modelling of shape,\npose and shading. International Journal of Computer Vision , 128(4):835\u2013854, 2020.\n[11] L Mi, M Shen, and J Zhang. A probe towards understanding gan and vae models. arxiv 2018. arXiv preprint\narXiv:1812.05676 .\n[12] Thu H Nguyen-Phuoc, Christian Richardt, Long Mai, Yongliang Yang, and Niloy Mitra. Blockgan: Learning 3d\nobject-aware scene representations from unlabelled images. Advances in neural information processing systems ,\n33:6767\u20136778, 2020.\n[13] Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li, Or Litany, Zan Gojcic, and\nSanja Fidler. Get3d: A generative model of high quality 3d textured shapes learned from images. Advances In\nNeural Information Processing Systems , 35:31841\u201331854, 2022.\n[14] Monica Welfert, Gowtham R Kurri, Kyle Otstot, and Lalitha Sankar. Addressing gan training instabilities via\ntunable classification losses. arXiv preprint arXiv:2310.18291 , 2023.\n[15] Cristian Sbrolli, Paolo Cudrano, Matteo Frosi, and Matteo Matteucci. Ic3d: Image-conditioned 3d diffusion for\nshape generation. arXiv preprint arXiv:2211.10865 , 2022.\n7", "mimetype": "text/plain", "start_char_idx": 2773, "end_char_idx": 4205, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "704f3ab1-21eb-4efa-b78d-fb227585de9e": {"__data__": {"id_": "704f3ab1-21eb-4efa-b78d-fb227585de9e", "embedding": null, "metadata": {"page_label": "8", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cf7ccebf-3aed-4c05-96ba-da12ac883181", "node_type": "4", "metadata": {"page_label": "8", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "161cb462ea97c35de69168a18345fcb06ea17e9fb958ea7da92c99d41defb29f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "badc9805-6d26-47eb-8c57-eeacedda51de", "node_type": "1", "metadata": {}, "hash": "18ef96aa2a8200a08aa5642644edcfebd0f241dec9a35a8f15df47e3d3458838", "class_name": "RelatedNodeInfo"}}, "text": "[16] Kristen M Edwards, Brandon Man, and Faez Ahmed. Sketch2prototype: rapid conceptual design exploration and\nprototyping with generative ai. Proceedings of the Design Society , 4:1989\u20131998, 2024.\n[17] Kevin Ma, Daniele Grandi, Christopher McComb, and Kosa Goucher-Lambert. Conceptual design generation\nusing large language models. In International Design Engineering Technical Conferences and Computers and\nInformation in Engineering Conference , volume 87349, page V006T06A021. American Society of Mechanical\nEngineers, 2023.\n[18] Vivian Liu, Jo Vermeulen, George Fitzmaurice, and Justin Matejka. 3dall-e: Integrating text-to-image ai in 3d\ndesign workflows. In Proceedings of the 2023 ACM designing interactive systems conference , pages 1955\u20131977,\n2023.\n[19] Herbert A Simon. The architecture of complexity. Proceedings of the American philosophical society , 106(6):467\u2013\n482, 1962.\n[20] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha\nDziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. Advances in\nNeural Information Processing Systems , 36, 2024.\n[21] Alexei Baevski and Michael Auli. Adaptive input representations for neural language modeling. arXiv preprint\narXiv:1809.10853 , 2018.\n[22] Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, and Oleksandr Skurzhanskyi. Gector\u2013\ngrammatical error correction: tag, not rewrite. arXiv preprint arXiv:2005.12592 , 2020.\n[23] Aman Madaan, Niket Tandon, Dheeraj Rajagopal, Peter Clark, Yiming Yang, and Eduard Hovy. Think about it!\nimproving defeasible reasoning by first modeling the question scenario. arXiv preprint arXiv:2110.12349 , 2021.\n[24] Meenal Parakh, Alisha Fong, Anthony Simeonov, Tao Chen, Abhishek Gupta, and Pulkit Agrawal. Lifelong robot\nlearning with human assisted language planners. In CoRL 2023 Workshop on Learning Effective Abstractions for\nPlanning (LEAP) , 2023.\n[25] Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and William Yang Wang. Automatically\ncorrecting large language models: Surveying the landscape of diverse self-correction strategies. arXiv preprint\narXiv:2308.03188 , 2023.\n[26] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.\n[27] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by\ngenerative pre-training. 2018.\n[28] Partha Pratim Ray. Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics,\nlimitations and future scope. Internet of Things and Cyber-Physical Systems , 2023.\n[29] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini\nAgarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback,\n2022. URL https://arxiv. org/abs/2203.02155 , 13:1, 2022.\n[30] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo\nAlmeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3186, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "badc9805-6d26-47eb-8c57-eeacedda51de": {"__data__": {"id_": "badc9805-6d26-47eb-8c57-eeacedda51de", "embedding": null, "metadata": {"page_label": "8", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cf7ccebf-3aed-4c05-96ba-da12ac883181", "node_type": "4", "metadata": {"page_label": "8", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "161cb462ea97c35de69168a18345fcb06ea17e9fb958ea7da92c99d41defb29f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "704f3ab1-21eb-4efa-b78d-fb227585de9e", "node_type": "1", "metadata": {"page_label": "8", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}, "hash": "764df7af2efa4d50ce96ff21c9ec829181c67ac3c6c067ced2a835c5fc4e5df1", "class_name": "RelatedNodeInfo"}}, "text": "Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics,\nlimitations and future scope. Internet of Things and Cyber-Physical Systems , 2023.\n[29] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini\nAgarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback,\n2022. URL https://arxiv. org/abs/2203.02155 , 13:1, 2022.\n[30] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo\nAlmeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint\narXiv:2303.08774 , 2023.\n[31] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-image pre-training\nwith frozen image encoders and large language models. In International conference on machine learning , pages\n19730\u201319742. PMLR, 2023.\n[32] FreeCAD \u2014 github.com. https://github.com/FreeCAD . [Accessed 02-05-2024].\n[33] GitHub - asweigart/pyautogui: A cross-platform GUI automation Python module for human beings. Used to pro-\ngrammatically control the mouse & keyboard. \u2014 github.com. https://github.com/asweigart/pyautogui.\ngit. [Accessed 31-03-2024].\n[34] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu,\nTal Remez, J\u00e9r\u00e9my Rapin, et al. Code llama: Open foundation models for code. arXiv preprint arXiv:2308.12950 ,\n2023.\n[35] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto,\nand Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys , 55(12):1\u201338,\n2023.\n8", "mimetype": "text/plain", "start_char_idx": 2561, "end_char_idx": 4282, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"635f3021-82ee-42ed-a18a-b87275b255cd": {"doc_hash": "e6148c00259359ab65ee04ec09b84d7253269ee9677017349019e906daec3dc1", "ref_doc_id": "c59b5c7f-8102-4ae2-ba20-052bf99eb4e1"}, "2dece173-f18e-4234-82b6-e8e8d3b461aa": {"doc_hash": "77106ae1c84d158af75ebb182ff0beee7de5f0a76e5b8b333c4ffda617254e42", "ref_doc_id": "773a6811-e18b-4a58-8a0b-1a1c4e789b0c"}, "d5cfbf8e-0bc6-4496-ad60-3ba587d4f9dc": {"doc_hash": "3545ca8428e11e25cac3145bedcf7e3dde6ea1e2ed6d3811edff740ced22b9c5", "ref_doc_id": "7cf2cad0-b01b-442c-a355-b4910b3cc475"}, "d9d65d48-6f13-42ef-a5b6-6c4305fe24e7": {"doc_hash": "53de9e2e50ce7b5ddff905c527d0c3114ec35cbaf7bb5713578d62bf044bd6bb", "ref_doc_id": "7cf2cad0-b01b-442c-a355-b4910b3cc475"}, "cde0aecb-346b-4949-9e50-1984abd456a0": {"doc_hash": "8fd57aa977a25032b0dda66e41afd2607bf9d1c95cba02e8336aaaf0c7ef4e37", "ref_doc_id": "9a897750-61b1-49fb-a62d-e2485fffb8d6"}, "655fc578-1694-4e4a-b349-c9c3eb3904bc": {"doc_hash": "955d0437cd5407092565e6cb16107b815bf72d7845b364fdbbb3c5f83a60f930", "ref_doc_id": "9a897750-61b1-49fb-a62d-e2485fffb8d6"}, "cf22d3f4-0052-4924-af01-cfdd9dac0921": {"doc_hash": "2ba8478cccd583ea71b2fe438002841878f4f804e0107ea47a69d9eb9735a154", "ref_doc_id": "7538d4cc-633e-4cd6-a6c4-c4fb6f5c1f10"}, "159bfe09-056d-411f-ad92-7b4c2f0b4a3d": {"doc_hash": "a720cd2392a933848ab25d6987c761206ad145aae7142e9804b78036669fbf54", "ref_doc_id": "b67424d1-ad15-4e02-bc19-0e403c097e5e"}, "5d5bb538-1a0e-419b-9d06-6ad736ffe6e5": {"doc_hash": "8495741c4bfc50d5e2532c11db62ab093aa68ba9c04fea2406b0afadee1ea010", "ref_doc_id": "3d9084ea-893c-4ce6-9fbf-025fbdb71a48"}, "3ecc5733-79d9-453a-8f74-f440e5d9a774": {"doc_hash": "609114cfa5977b49af1145756679be11a9eea74c611f98f76ddecd8136c54b49", "ref_doc_id": "3d9084ea-893c-4ce6-9fbf-025fbdb71a48"}, "704f3ab1-21eb-4efa-b78d-fb227585de9e": {"doc_hash": "764df7af2efa4d50ce96ff21c9ec829181c67ac3c6c067ced2a835c5fc4e5df1", "ref_doc_id": "cf7ccebf-3aed-4c05-96ba-da12ac883181"}, "badc9805-6d26-47eb-8c57-eeacedda51de": {"doc_hash": "c95dade4003a4fb06d9e6ab5fd586bb044e11230e0fd6c035bc642e13ccfb2dd", "ref_doc_id": "cf7ccebf-3aed-4c05-96ba-da12ac883181"}}, "docstore/ref_doc_info": {"c59b5c7f-8102-4ae2-ba20-052bf99eb4e1": {"node_ids": ["635f3021-82ee-42ed-a18a-b87275b255cd"], "metadata": {"page_label": "1", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "773a6811-e18b-4a58-8a0b-1a1c4e789b0c": {"node_ids": ["2dece173-f18e-4234-82b6-e8e8d3b461aa"], "metadata": {"page_label": "2", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "7cf2cad0-b01b-442c-a355-b4910b3cc475": {"node_ids": ["d5cfbf8e-0bc6-4496-ad60-3ba587d4f9dc", "d9d65d48-6f13-42ef-a5b6-6c4305fe24e7"], "metadata": {"page_label": "3", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "9a897750-61b1-49fb-a62d-e2485fffb8d6": {"node_ids": ["cde0aecb-346b-4949-9e50-1984abd456a0", "655fc578-1694-4e4a-b349-c9c3eb3904bc"], "metadata": {"page_label": "4", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "7538d4cc-633e-4cd6-a6c4-c4fb6f5c1f10": {"node_ids": ["cf22d3f4-0052-4924-af01-cfdd9dac0921"], "metadata": {"page_label": "5", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "b67424d1-ad15-4e02-bc19-0e403c097e5e": {"node_ids": ["159bfe09-056d-411f-ad92-7b4c2f0b4a3d"], "metadata": {"page_label": "6", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "3d9084ea-893c-4ce6-9fbf-025fbdb71a48": {"node_ids": ["5d5bb538-1a0e-419b-9d06-6ad736ffe6e5", "3ecc5733-79d9-453a-8f74-f440e5d9a774"], "metadata": {"page_label": "7", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}, "cf7ccebf-3aed-4c05-96ba-da12ac883181": {"node_ids": ["704f3ab1-21eb-4efa-b78d-fb227585de9e", "badc9805-6d26-47eb-8c57-eeacedda51de"], "metadata": {"page_label": "8", "file_name": "QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_path": "D:\\NIRMAL PRASAD PANTA\\ANK\\RAGwithllama\\Learning\\Research_Papers\\QUERY2CAD GENERATING CAD MODELS USING NATURAL.pdf", "file_type": "application/pdf", "file_size": 437414, "creation_date": "2024-06-26", "last_modified_date": "2024-06-10"}}}}