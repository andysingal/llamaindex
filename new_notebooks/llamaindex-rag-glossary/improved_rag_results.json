{"question":{"0":"What is the similarity map?","1":"How can I install Renumics Spotlight?","2":"I want to find duplicates in my data. How can I do this?","3":"Which possibilities regarding cluster analysis does Spotlight offer and how can it help me?","4":"I want to identify label issues for my audio use case? Which features and visualizations can help me and how could the process look?","5":"What are the main UI elements that help me with my use case in Spotlight?","6":"What is the Inspector and how does it play together with other components?","7":"What is sliceguard and how does it play together with Spotlight?","8":"I want to look at my audio data. Which possibilities does Spotlight offer?","9":"How can I customize the data visualization in Renumics Spotlight?","10":"Which possibilities for data loading and export does Renumics Spotlight offer?"},"ground_truth":{"0":"The similarity map is a dimensionality reduction plot that displays high dimensional data like embeddings in 2D space. It can be very useful for getting a first overview on dataset structure and possible problems, before diving into more detailed analysis.","1":"Just run pip install renumics-spotlight. After that, start it by running spotlight from the CLI or use the Python interface via spotlight.show.","2":"You can either just do that exploratively, e.g. by placing data on the similarity map and checking if nearby datapoints are identical via the inspector. You can also detect duplicates with specialized tooling like annoy and display the results in spotlight via spotlight.show.","3":"Spotlight offers the similarity map, which can display embeddings or feature arrays in 2D. You can then identify clusters visually and browse through them while looking at the underlying data such as images or audio files in the inspector.","4":"Similarity Map, Inspector and Filtering can help you with that. You could simply place your data points on the similarity map using an general purpose audio embedding. You could then color the data points by label. If there are clusters with mixed labels, that's a sign for label issues. You could also train a model on the existing labels and then color by model error, which is a great way of pinpointing the issues even faster.","5":"The main elements are the table for exploring data points by their metadata, the inspector for displaying unstructured data, the filter bar for filtering the data, The similarity map as an overview plot on the dataset structure, and potentially multiple additional visualizations such as histograms or scatterplots, as well as metric display elements such as a confusion matrix.","6":"It is Spotlight's UI component that is able to display unstructured data such as images, audio files, text, and more. It can be used to easily explore unstructured, multimodal datasets.","7":"It is a library that can automatically detect data clusters or slices where a machine learning model does not perform well. It uses Spoglight to display its detection results. It is also built by Renumics.","8":"You can display audio data in the inspector. Spotlight offers the visualizations audio player and spetrogram. It can also display windows in which a certain event in the audio data occurs. To visualize audio dataset structure you could use audio embeddings that are displayed on the Similarity Map.","9":"You can configure the UI flexibly via the UI. This involves configuring a layout with different widgets and plots, as well as adding lenses to the inspector widget. You can also save and load configured layouts either via json files or via the python API.","10":"Spotlight can load pandas dataframes and huggingface datasets via spotlight.show. It can also load hdf5 files (legacy) and csv files. The preferred way is directly loading pandas dataframes via spotlight.show."},"answer":{"0":" The Similarity Map is a widget in Renumics Spotlight that projects high-dimensional data from datasets onto a 2D map for visualization. It uses the similarity of selected columns to place the data points. This map can be customized through controls like zooming, panning, coloring, and sizing. It is particularly useful for data-centric AI tasks such as identifying critical clusters in the data or dealing with duplicates in common Arrows tables that contain features like images, audio, and additional task-specific metadata. Spotlight directly works on top of datasets, allowing for efficient, client-side data analytics without the need for copying or pre-processing the dataset. Data types and label mappings can be inferred directly from the dataset or manually assigned using the Spotlight API. For more details on supported data types and detailed examples, please refer to the Renumics Spotlight documentation.","1":" To install Renumics Spotlight, you can use pip by running the command `pip install renumics-spotlight` in your terminal or command prompt. It's recommended to create and use a Python virtual environment for your project before installing Spotlight. After installation, you can load your dataset into Spotlight using the Python API or the command-line interface (CLI). For more details on loading data and using the various features of Renumics Spotlight like inspector widgets, similarity maps, data tables, and filters, refer to the documentation provided in the \/docs\/getting\\_started\/index.mdx file.\n\nAdditionally, to explore an enriched dataset with custom visualization layouts, you can join your raw dataset with model results such as predictions or embeddings in a separate dataframe using the Huggingface hub. Depending on the task at hand, you may want to set up a suitable visualization layout in the GUI or via API. For development, you'll need to install both Python with Poetry and Node.js with Pnpm. After setting up the Spotlight repository and installing development dependencies, you can submit your improvements, fixes, and new features to Spotlight by creating a Pull Request. To make development easier, you can also use Direnv to automatically set up the environment when entering the Spotlight folder.","2":" To find duplicates in your data using Renumics Spotlight, you can utilize the Annoy library for embedding space indexing and detection. This method can be applied to both text and image data. Here's how you can modify the provided example to work with text data:\n\n1. First, install the required packages:\n\n```bash\npip install renumics-spotlight datasets annoy\n```\n\n2. Create a function to find nearest neighbors for text data:\n\n```python\nimport datasets\nfrom renumics import spotlight\nfrom annoy import AnnoyIndex\nimport pandas as pd\nimport numpy as np\nimport jaro_distance\nimport json\nimport os\nimport string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import MiniBatchKMeans\n\ndef preprocess_text(text):\n    # Preprocessing text data\n    text = text.lower()\n    text = re.sub(r'\\[.*?\\]', '', text) # remove square brackets\n    text = re.sub(r'\\(.*?\\)', '', text) # remove parentheses\n    text = re.sub(r'\\d+', 'number', text) # replace digits with 'number'\n    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n    text = ' '.join(word for word in text.split() if word not in stopwords.words('english')) # remove stopwords\n    text = WordNetLemmatizer().lemmatize(text) # lemmatize words\n    return text\n\ndef nearest_neighbor_annoy_text(df, text_column='text', threshold=0.5, tree_size=100):\n    # Preprocess text data\n    df[text_column] = df[text_column].apply(preprocess_text)\n    text_vectors = np.array(TfidfVectorizer().fit_transform(df[text_column]).toarray())\n\n    t = AnnoyIndex(len(text_vectors[0]), 'angular')\n\n    for idx, x in enumerate(text_vectors):\n        t.add_item(idx, x)\n\n    t.build(tree_size)\n\n    df_nn = pd.DataFrame()\n\n    nn_id = [t.get_nns_by_item(i,2)[1] for i in range(len(text_vectors))]\n    df_nn['nn_id'] = nn_id\n    df_nn['nn_text'] = [df['text'][i] for i in nn_id]\n    df_nn['nn_distance'] = np.array([t.get_distance(i, nn_id[i]) for i in range(len(text_vectors))])\n    df_nn['nn_flag'] = (df_nn.nn_distance < threshold)\n\n    return df_nn\n```\n\n3. Use the function to find duplicates:\n\n```python\n# Load your data into a pandas DataFrame\ndf = pd.read_csv('your_data.csv')\n\n# Find nearest neighbors and duplicates\ndf_nn = nearest_neighbor_annoy_text(df)\ndf = pd.concat([df, df_nn], axis=1)\n```\n\n4. Visualize the results using Renumics Spotlight:\n\n```python\n# Install Spotlight if you haven't already\n!pip install renumics-spotlight\n\n# Load the data into Spotlight\nspotlight_data = spotlight.DataFrame(df)\n\n# Create a layout with a DataTable and an Inspector Widget\nlayout = spotlight.Layout(spotlight_data)\nlayout.add_widget(spotlight.DataTable(spotlight_data))\nlayout.add_widget(spotlight.InspectorWidget(spotlight_data))\n\n# Show the layout in your browser\nspotlight.show(layout)\n```\n\nThis will display the original data in the DataTable and the nearest neighbors in the Inspector Widget. You can use the Inspector Widget to examine the text data of both the original data point and its nearest neighbor. If the 'nn_flag' column in the DataFrame is True, then the data point is considered a duplicate based on the threshold you set.","3":" Spotlight offers various possibilities for cluster analysis through its UI components and features. One of the key components for cluster analysis is the Similarity Map. It is a dimensionality reduction plot that helps display high-dimensional data with additional dimensions displayable via coloring. Data Point Selection in the Similarity Map allows users to select, deselect, and highlight individual or groups of data points for detailed analysis. Map Customization options enable users to adjust the visualization through controls like zooming, panning, coloring, and sizing, tailored to specific data attributes.\n\nAnother supportive view for analyzing correlations between metadata is the Scatter Plot, which can be customized with aspects like dot size and color. The Histogram view can be stacked to provide insights into data segments over two dimensions, useful for data distribution analysis.\n\nThe Filter Bar component enables data filtering based on feature values, impacting the presentation in other components. This can greatly help in analyzing and reasoning about your data.\n\nFor advanced customization and automation within the user interface, Spotlight provides a Python API for Layout. This allows users to build and customize layouts programmatically.\n\nAdditionally, Spotlight offers an Inspector Widget for detailed examination and editing of the features of individual data points, supporting multiple data types and views. Data Modality Views within the Inspector Widget cater to different types of data, enabling specialized inspection and interaction for unstructured data like text, audio, image, and 3D geometries.\n\nData Issues in Spotlight refer to potential issues linking to certain data points within the spotlight dataset. These issues can have additional attributes like an issue title, description, and severity. Examples of data issues could be data duplicates or clusters where the model performs badly.","4":" To identify label issues for your audio use case in Renumics Spotlight, you can utilize the following features and visualizations:\n\n1. **Data-centric AI**: Focus on the iterative improvement of your dataset for enhancing the training and evaluation of your audio classification model.\n2. **Data Issues**: Spotlight can detect various data issues related to your audio dataset, such as label inconsistencies, outliers, and audio-specific issues like clipping.\n3. **Data Table**: This primary view in Spotlight shows your data with various control options, allowing you to edit data points, including creating new columns if needed.\n4. **Filter Bar**: Use this component to filter your data based on feature values, which can impact the presentation in other components and help you focus on specific data points.\n5. **Scatter Plot**: Analyze correlations between metadata in a scatter plot to identify potential label issues or patterns in your dataset.\n6. **Histogram**: Use histograms to gain insights into data segments over two dimensions, which can be useful for data distribution analysis and identifying label inconsistencies.\n7. **Sliceguard**: This library can be used to detect problem clusters in your audio dataset, which can cause issues when training your model. It shows problems such as label inconsistencies, outliers, and audio-specific issues like clipping.\n8. **Inspector Widget**: This component allows detailed examination and editing of the features of individual data points in various data modalities like audio, image, text, and 3D geometries.\n9. **Data Modality Views**: Use data modality views within the Inspector Widget to display different modalities of your data points, especially unstructured data like audio, for specialized inspection and interaction.\n10. **Similarity Map**: This dimensionality reduction plot can be used to display high-dimensional data with additional dimensions displayable via coloring. It can help you identify potential label issues by allowing you to select, deselect, and highlight individual or groups of data points for detailed analysis.\n11. **Map Customization**: Customize the visualization in the Similarity Map through controls like zooming, panning, coloring, and sizing to better understand the relationships between your data points and their labels.\n12. **Layout**: Customize your workspace by adding, removing, resizing, and renaming widgets to create an efficient workflow for identifying and addressing label issues in your audio dataset.\n13. **Python API for Layout**: Use the provided Python API to build and customize layouts programmatically for advanced customization and automation within the user interface.\n\nThe process of identifying label issues in your audio dataset using these features and visualizations would involve loading your dataset into Spotlight, exploring the data using the various views and controls, and addressing any issues you identify by editing the data directly in Spotlight or exporting it for further processing.\n\nWith the provided context, you can also use the `cv_issues_cleanvision` function to compute heuristics for typical audio data error scores with Cleanvision and then inspect the errors and detect problematic data segments with Spotlight. This can be done by loading the CIFAR-100 dataset from Huggingface hub, converting it to a Pandas dataframe, computing the heuristics using the `cv_issues_cleanvision` function, and then visualizing the results in Spotlight.","5":" The main UI elements that can help you with your use case in Spotlight include the Inspector Widget, Data Table, Filter Bar, Similarity Map, Scatter Plot, Histogram, Layout, Audio Player, and Spectrogram. The Inspector Widget lets you examine and edit the features of individual data points with multiple views for different modalities such as text, audio, image, and 3D geometry data. The Data Table is the primary view in Spotlight that shows data with various control options and allows editing of data points. The Filter Bar enables data filtering based on feature values, impacting the presentation in other components. The Similarity Map is used for displaying high-dimensional data with additional dimensions displayable via coloring, and it supports data point selection, deselection, and highlighting for detailed analysis. The Scatter Plot analyzes correlations between metadata with customizable aspects like dot size and color. The Histogram provides insights into data segments over two dimensions, useful for data distribution analysis. For audio data specifically, the Audio Player and Spectrogram can be used to represent and analyze the data. The Audio Player supports annotating event windows in the data, while the Spectrogram displays the spectral representation of the audio signal.","6":" The Inspector Widget in Renumics Spotlight is a powerful component that allows for detailed examination and editing of individual data points in your dataset. It provides multiple views for different modalities such as text, audio, image, video, and 3D geometry data, enabling you to explore and edit data points in depth. The Inspector Widget plays an essential role in the Data-centric AI approach by allowing users to identify and address data issues such as duplicates or data points with poor model performance. It can be integrated with other components like the Data Table, Filter Bar, Scatter Plot, and Histogram to provide a comprehensive analysis of your dataset.\n\nMoreover, the Inspector Widget supports various data modality views, including lenses for arrays, sequences, meshes, images, videos, audio, windowed audio, spectrograms, and windowed spectrograms. These views enable specialized inspection and interaction for different data types.\n\nThe provided code snippet demonstrates the usage of various lenses for different data types within the Inspector Widget:\n```python\nInspector(\n    data=df,\n    lenses=[\n        lenses.array(\"array\"),\n        ...             lenses.sequences(\"sequence\"),\n        ...             lenses.sequences([\"sequence1\", \"sequence2\"], name=\"sequences\"),\n        ...             lenses.mesh(\"mesh\"),\n        ...             lenses.image(\"image\"),\n        ...             lenses.video(\"video\"),\n        ...             lenses.audio(\"audio\"),\n        ...             lenses.audio(\"audio\", window_column=\"window\", name=\"windowed audio\"),\n        ...             lenses.spectrogram(\"audio\"),\n        ...             lenses.spectrogram(\n        ...                 \"audio\",\n        ...                 window_column=\"window\",\n        ...                 name=\"windowed spectrogram\",\n        ...             ),\n        ...         ],\n    num_columns=2,\n)\n```\nThis Inspector Widget configuration allows users to inspect various data types with ease and flexibility, making it an indispensable tool for working with multimodal datasets and ensuring data quality in the Data-centric AI approach.","7":" Sliceguard is an open-source library for data-centric AI that helps identify data slices where machine learning models, specifically text classification models in this case, perform anomalously. It uses statistical methods to find data segments that deviate significantly from the overall distribution of the data. Sliceguard can be used to explore these data slices and find model failure modes and problematic data segments related to issues such as label inconsistencies, outliers and errors, and text-specific issues like typos or empty samples.\n\nSpotlight is another open-source library from Renumics that provides an interactive data exploration platform for machine learning datasets. It allows users to visualize and analyze data using various widgets like scatter plots, histograms, similarity maps, and more. Spotlight enables users to filter, edit, and customize the layout of the data to gain insights into data distributions and identify issues.\n\nSliceguard plays together with Spotlight by providing data slices that can be explored in Spotlight to find potential issues in the text classification data. Sliceguard identifies data slices based on statistical anomalies, while Spotlight provides the interactive interface for visualizing and analyzing these slices to gain deeper insights into the data and the issues it contains. Together, these libraries enable users to effectively address data issues that can impact machine learning model performance in text classification tasks.","8":" Spotlight offers two possibilities for looking at audio data: an Audio Player and a Spectrogram viewer. The Audio Player supports annotating event windows in the data, while the Spectrogram viewer displays the audio data in the frequency domain with the option to show the corresponding time domain waveform. Both views can be found in the Inspector Widget of Spotlight, which is a component that lets you examine and edit the features of individual data points in detail. The Inspector Widget supports multiple data types and views, including those for text, categorical data, image data, and audio data.","9":" To customize the data visualization in Renumics Spotlight, you can use various components and features available in the platform. Here's an expanded overview:\n\n1. **Layout**: Renumics Spotlight's layout system allows users to customize their workspace by adding, removing, resizing, and renaming widgets. Users can save, load, or reset these arrangements for future use. The platform also provides a Python API for advanced layout customization and automation within the user interface.\n2. **Inspector Widget**: The Inspector Widget offers detailed examination and editing of individual data points' features, supporting multiple data types and views for text, audio, image, and 3D geometries. It's particularly useful for displaying different modalities of a data point, especially unstructured data.\n3. **Data Modality Views**: The Inspector Widget includes specific views for different types of data, such as text, audio, image, and 3D geometries. These views enable specialized inspection and interaction for each data type.\n4. **Filter Bar**: The Filter Bar enables data filtering based on feature values, impacting the presentation in other components and greatly helping in analyzing and reasoning about your data.\n5. **UI Components**: Renumics Spotlight offers various visualization options like the Similarity Map, Scatter Plot, Histogram, and Data Table to help you analyze and understand individual data points and the overall distribution of your data.\n6. **Map Customization**: In the Similarity Map, users can adjust visualization through controls like zooming, panning, coloring, and sizing tailored to specific data attributes.\n7. **Data-centric AI**: Renumics Spotlight focuses on the iterative improvement of datasets for enhancing the training and evaluation of machine learning models. Customizing the data visualization can help in identifying data issues and improving data quality for better model performance.\n8. **Layout Customization**: Spotlight's layout system enables users to customize their workspace by adding, removing, resizing, and renaming widgets. Users can save, load, or reset these arrangements using the layout button in the top right corner of the window. Additionally, the platform provides a Python API for advanced layout customization and automation within the user interface.\n9. **Add and Delete Widget**: Users can add widgets to an existing Tab group by clicking on the + button in the top of the Tab group, while deleting a widget involves clicking on the x button in the top of the Widget.\n10. **Resize Widgets**: To resize a widget, simply drag the widget's border and move it to the desired size. Users can also put a widget to fullscreen mode by clicking on the maximize\/minimize button.\n11. **Move and Stack Widgets**: Users can move a widget by dragging the widget's title bar to the desired position. They can also stack widgets by dragging one widget on top of another.\n12. **Rename Widgets**: To rename a widget, simply double-click on the widget's title bar and type in the new name.","10":" Renumics Spotlight offers various possibilities for data loading and export to support Data-centric AI:\n\n1. Data can be loaded into Spotlight from different formats such as CSV, Parquet, Feather, ORC (through Pandas), Pandas in memory, Huggingface datasets, and Spotlight datasets based on the HDF5-Format using both the Python API and Command Line Interface (CLI).\n2. Users can load data via the Python API or the command-line interface (CLI), with automatic parsing of data type descriptions and label mappings for Huggingface datasets.\n3. Data can be exported using the Python API for further processing or analysis.\n4. Custom data visualizations (Widgets) such as scatter plots, histograms, or similarity maps can be loaded within the UI.\n5. Data-centric AI features like Data Point Selection, Map Customization, Filter Bar, and Data Issues can be used to identify critical clusters and improve the quality of datasets for enhancing the training and evaluation of machine learning models.\n6. Users can load in-memory datasets for efficient analysis when working in a notebook.\n7. Spotlight supports a wide range of data types for both tabular and unstructured data types, with the option to manually specify data types for certain columns.\n8. Detailed descriptions on how to load Pandas dataframes, Huggingface datasets, and Spotlight HDF5 datasets can be found in the provided documentation."},"contexts":{"0":["`similaritymap(name=None, columns=None, reduction_method=None, color_by_column=None, size_by_column=None, filter=False, *, umap_metric=None, umap_balance=None, pca_normalization=None)` {similaritymap()}\n\nAdd configured similarity map to Spotlight layout.","---\ntags: []\nid: similarity-map\nsidebar_position: 30\nslug: \/docs\/custom-visualizations\/ui-components\/similarity-map\n---\n\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Similarity Map\n\nThe Similarity Map projects the datapoints onto a 2D Map based on the similarity of the selected columns to place by. The Similarity is measured by either pre computed descriptions (e.G. embeddings retrieved from a ML workflow) or based on one or multiple scalar columns in the dataset.\n\n## Placement\n\nSimply select one ore more columns to \u2018placeBy\u2019 in the settings and watch the dimension reduction arranging the data on the map.\n\nIn order to compute the dimension reduction we offer two different algorithms:\n[UMAP](https:\/\/arxiv.org\/abs\/1802.03426) and [PCA](https:\/\/en.wikipedia.org\/wiki\/Principal_component_analysis).\nIf the columns values have different distributions,\nThe reduction might run into problems and overestimate the impact of some columns.\nTo counteract this problem, a robust distance metric is available in the advanced settings.\n\nPer default only reduced settings are available to control UMAP\nwhich help you in configuring the reduction to place the samples with more weight on local vs. global similarities.\nHowever, there also are advanced settings available in order give more control over the dimension reduction.\n\nAt the moment the samples can be placed by number columns and Embedding\/Array columns.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/similarity-map\/placement\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_ - place datapoints on the **similarity map** based on a column\"\n\/>\n\n## Controls\n\nThe map can be moved and zoomed by using the mouse.\n\nZooming can be done with the mousewheel, resetting zoom can be done with the `Fit points` button.\n\nThe map can be moved by clicking the `middle mouse` button or with the `left mouse` button if the `alt` key is pressed simultaneously.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/similarity-map\/controls\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_ - navigate in the **similarity map**\"\n\/>\n\n## Selection\n\nSimilar to the [data table](data-table), a single row can be added or removed from the selection.\n\nIn order to select a single point simply click on it. This will reset any selection and exclusively select the clicked point.\n\nTo add a point to a selection click on it while pressing `shift` and to remove it press `ctrl` while clicking on it.\n\nThese steps also apply for multiple points. By pressing the left mouse button and moving the mouse,\na selection rectangle will be shown. On releasing the left mouse button, the selection will be applied in the same fashion as it is done for a single point.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/similarity-map\/selection\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_ - select and deselect points in the **similarity map**\"\n\/>\n\n## Coloring and Sizing\n\nColoring and sizing can be used to represent more columns on the map. The coloring palette can be altered in the global coloring settings.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/similarity-map\/coloring-scaling\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_ - colorize and scale datapoints on the **similarity map** based on a column\"\n\/>\n\n## Filtering\n\nPer default the similarity map also accounts for similarities of filtered out points.\nIn order to compute the similarities only on the filtered points,\n`hide unfiltered` has to be checked.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/similarity-map\/filtering\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_ - show\/hide filtered datapoints on the **similarity map**\"\n\/>","---\ntitle: \ud83e\udd17 Loading Huggingface Data\nslug: \/docs\/loading-data\/huggingface\nsidebar_position: 30\n---\n\n# Loading Data from Huggingface datasets\n\n![Huggingface example](\/img\/speech_commands_vis_s.gif)\n\nThe Hugging Face datasets library not only provides access to more than 70k publicly available datasets, but also offers very convenient data preparation pipelines for custom datasets.\n\nRenumics Spotlight allows you to create interactive visualizations to identify critical clusters in your data. Because Spotlight understands the data semantics within Hugging Face datasets, you can get started with just one line of code:\n\n```python\nimport datasets\nfrom renumics import spotlight\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='validation')\n\nspotlight.show(ds)\n```\n\n## Spotlight \ud83e\udd1d Hugging Face datasets\n\nThe datasets library has several features that makes it an ideal tool for working with ML datasets: It stores tabular data (e.g. metadata, labels) along with unstructured data (e.g. images, audio) in a common Arrows table. Datasets also describes important data semantics through features (e.g. images, audio) and additional task-specific metadata.\n\nSpotlight directly works on top of the datasets library. This means that there is no need to copy or pre-process the dataset for data visualization and inspection. Spotlight loads the tabular data into memory to allow for efficient, client-side data analytics. Memory-intensive unstructured data samples (e.g. audio, images, video) are loaded lazily on demand. In most cases, data types and label mappings are inferred directly from the dataset. Here, we visualize the CIFAR-100 dataset with one line of code:\n\n```python\nds = datasets.load_dataset('cifar100', split='test')\nspotlight.show(ds)\n```\n\nIn cases where the data types are ambiguous or not specified, the Spotlight API allows to manually assign them:\n\n```python\nlabel_mapping = dict(zip(ds.features['fine_label'].names, range(len(ds.features['fine_label'].names))))\nspotlight.show(ds, dtype={'img': spotlight.Image, 'fine_label': spotlight.dtypes.CategoryDType(categories=label_mapping)})\n```\n\n## Supported data types\n\nMore details on the supported data types can be found in the [data types section](..\/loading-data#supported-data-types)\n\n## Detailed examples\n\nTake a look at our [use case section](..\/use-cases) to find more detailed examples for different modalities."],"1":["`inspector(name=None, lenses=None, num_columns=4)` {inspector()}\n\nAdd an inspector widget with optionally preconfigured viewers (lenses).\n\n Example\n\n```python\n>>> from renumics.spotlight import layout\n>>> from renumics.spotlight.layout import lenses\n>>> spotlight_layout = layout.layout(\n...     layout.inspector(\n...         \"My Inspector\",\n...         [\n...             lenses.scalar(\"bool\"),\n...             lenses.scalar(\"float\"),\n...             lenses.scalar(\"str\"),\n...             lenses.scalar(\"datetime\"),\n...             lenses.scalar(\"category\"),\n...             lenses.scalar(\"int\"),\n...             lenses.text(\"str\", name=\"text\"),\n...             lenses.html(\"str\", name=\"HTML (safe)\"),\n...             lenses.html(\"str\", name=\"HTML\", unsafe=True),\n...             lenses.markdown(\"str\", name=\"MD\"),\n...             lenses.array(\"embedding\"),\n...             lenses.array(\"window\"),\n...             lenses.array(\"array\"),\n...             lenses.sequences(\"sequence\"),\n...             lenses.sequences([\"sequence1\", \"sequence2\"], name=\"sequences\"),\n...             lenses.mesh(\"mesh\"),\n...             lenses.image(\"image\"),\n...             lenses.video(\"video\"),\n...             lenses.audio(\"audio\"),\n...             lenses.audio(\"audio\", window_column=\"window\", name=\"windowed audio\"),\n...             lenses.spectrogram(\"audio\"),\n...             lenses.spectrogram(\n...                 \"audio\",\n...                 window_column=\"window\",\n...                 name=\"windowed spectrogram\",\n...             ),\n...         ],\n...         num_columns=2,\n...     )\n... )\n```","---\nslug: \/docs\/getting-started\nsidebar_position: 10\n---\n\nimport ReactPlayer from \"react-player\";\nimport Tabs from \"@theme\/Tabs\";\nimport TabItem from \"@theme\/TabItem\";\n\n# \ud83d\ude80 Getting Started\n\n> Spotlight helps you to **understand unstructured datasets** fast. You can create **interactive visualizations** from your dataframe with just a few lines of code. You can also leverage data enrichments (e.g. embeddings, prediction, uncertainties) to **identify critical clusters** in your data.\n\n![Dataframe example](\/img\/speech_commands_vis_s.gif)\n\n## What you'll need\n\n-   [Python](https:\/\/www.python.org\/downloads\/) version 3.8-3.11\n\n## Install Spotlight via [pip](https:\/\/packaging.python.org\/en\/latest\/key_projects\/#pip)\n\n```bash\npip install renumics-spotlight\n```\n\n> We recommend installing Spotlight and everything you need to work on your data in a separate [virtual environment](https:\/\/docs.python.org\/3\/tutorial\/venv.html)\n\n## Load your first dataset\n\nData can be loaded into Spotlight either from memory (as Python object) or from file. We currently support Pandas dataframes as well as Huggingface datasets and our own HDF5-based dataset format. Depending on the format, unstructured data samples are either stored directly in the dataframe or as a path to a separate file.\n\nThis is an example how your dataframe might look like:\n\n![Dataframe example](\/img\/dataframe_head_sample.png)\n\nYou can directly load your dataframe either via the Python API or the command line interface (CLI):\n\n<Tabs groupId=\"interface\">\n<TabItem value=\"python\" label=\"python\" default>\n\n```python\nimport pandas as pd\nfrom renumics import spotlight\n\ndf = pd.read_csv(\"https:\/\/renumics.com\/data\/mnist\/mnist-tiny.csv\")\nspotlight.show(df, dtype={\"image\": spotlight.Image, \"embedding\": spotlight.Embedding})\n```\n\n-   `pd.read_csv` loads a sample csv file as a pandas [DataFrame](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.html).\n-   `spotlight.show` opens up spotlight in the browser with the pandas dataframe ready for you to explore.\n-   The `dtype` argument specifies custom column types for the browser viewer.\n\n<\/TabItem>\n<TabItem value=\"bash\" label=\"CLI\">\n\n```bash\ncurl https:\/\/renumics.com\/data\/mnist\/mnist-tiny.csv -o mnist-tiny.csv\nspotlight mnist-tiny.csv --dtype image=Image --dtype embedding=Embedding\n```\n\n<\/TabItem>\n<\/Tabs>\n\n## Load a [Hugging Face](https:\/\/huggingface.co\/) dataset\n\nHuggingface datasets have a rich semantic description of the feature columns. Spotlight can thus parse data type descriptions and label mappings automatically. This means that creating a visualization is typically as simple as:\n\n```python\nimport datasets\nfrom renumics import spotlight\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='all')\n\nspotlight.show(ds)\n```\n\n## Exploring an enriched dataset with custom visualization layouts\n\nExploring raw unstructured datasets often yield little insights. Leveraging model results such as predictions or embeddings can help to uncover critical data samples and clusters. In practice, these enrichments can be stored in a separate dataframe and then joined with the raw dataset. Here is an example from the Huggingface hub:\n\n```python\nimport datasets\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='all')\nds_results = datasets.load_dataset('renumics\/speech_commands-ast-finetuned-results', 'v0.01', split='all')\nds = datasets.concatenate_datasets([ds, ds_results], axis=1)\n```\n\nDepending on the task at hand (e.g. EDA, model debugging, monitoring), you probably want to set up a suitable visualization layout. You can do so in the GUI and via API.","---\nslug: \/docs\/development\ntitle: Contributing to Spotlight\n---\n\n## Setting up Spotlight for development\n\nIn order to start development in spotlight as of now the easiest method is\nto checkout the repository and install development dependencies.\n\nThe spotlight backend is a [FastAPI](https:\/\/fastapi.tiangolo.com\/em\/) server written in `python`, serving the dataset\nand the frontend.<br \/>\nThe frontend is a [React](https:\/\/reactjs.org\/) application written in `typescript`.\n\nTherefore, for development, you'll need to install both `python` together with `poetry`\nand `nodejs` with `pnpm` to get started.\n\n:::info\nIf you want to contribute to spotlight in any form and struggle anywhere along the way please reach out to us.\n\nWe are more than happy to help out and guide you through the process.\n:::\n\n### Install dependencies\n\n#### Developing on Linux\n\nInstall [python3](https:\/\/www.python.org\/) together with [poetry](https:\/\/python-poetry.org\/docs\/)\n\n```bash\nsudo apt update\nsudo apt install python3 python3-dev\ncurl -sSL https:\/\/install.python-poetry.org | python3 -\n```\n\nInstall [nodejs](https:\/\/nodejs.org\/en\/) together with [pnpm](https:\/\/pnpm.io\/)\n\n```bash\nsudo apt install nodejs\ncurl -fsSL https:\/\/get.pnpm.io\/install.sh | sh -\n\n# check your installed node version\nnode -v\n```\n\nWe recommend using at least node version 18.\nIn order to install the latest version check out [NodeSource on Github](https:\/\/github.com\/nodesource\/distributions)\n\nYou might need to restart your terminal in order to use `pnpm` as a command.\n\n### Setup Spotlight Repository\n\nVisit the [spotlight repository](https:\/\/github.com\/Renumics\/spotlight) and click **Fork**.\nSetup your forked repository by cloning it and adding spotlight as an additional remote.\n\n```bash\ngit clone https:\/\/github.com\/YOUR_GIT_USERNAME\/spotlight.git\ncd spotlight\ngit remote add upstream https:\/\/github.com\/renumics\/spotlight.git\n```\n\nInside the spotlight repository you'll find a `Makefile` which contains all the commands to get you started.\nFirst install development dependencies and pre-commit.\n\n```bash\nmake init\n```\n\nand run the development server\n\n```bash\nmake dev\n```\n\n## Submit your work\n\nPlease make sure that you have [pre-commit](https:\/\/pre-commit.com\/) hooks installed and\nthat the hooks successfully ran for the added changes.<br \/>\nThis can be verified by creating a commit and checking if automated tests are run before the commit is created.\n\n```bash\npoetry run pre-commit install --hook-type pre-commit\npoetry run pre-commit install --hook-type pre-push\n```\n\nSubmit your improvements, fixes and new features to Spotlight by creating a\n[Pull Request](https:\/\/opensource.guide\/how-to-contribute\/#opening-a-pull-request).\n\n## Using [direnv](https:\/\/direnv.net\/)\n\nIn order to make development easier [direnv](https:\/\/direnv.net\/) can be used to automatically setup the environment\non entering the spotlight folder.\n\nThe provided [.envrc](https:\/\/github.com\/Renumics\/spotlight\/blob\/main\/.envrc) file automatically activates\nthe poetry environment and sets environment variables in .env and .env.local."],"2":["---\ntags: []\nid: duplicates-annoy\nsidebar_position: 35\nslug: \/docs\/data-centric-ai\/playbook\/duplicates-annoy\n---\n\nimport Tabs from \"@theme\/Tabs\";\nimport TabItem from \"@theme\/TabItem\";\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Detect duplicates with Annoy\n\nWe use embeddings to detect duplicates by computing nearest neighbors with the Annoy library. Although the example is based on image embeddings, the basic play is independent of the data type.\n\n> Use Chrome to run Spotlight in Colab. Due to Colab restrictions (e.g. no websocket support), the performance is limited. Run the notebook locally for the full Spotlight experience.\n\n<a\n    target=\"_blank\"\n    href=\"https:\/\/colab.research.google.com\/github\/Renumics\/spotlight\/blob\/main\/playbook\/veteran\/duplicates_annoy.ipynb\"\n>\n    <img\n        src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\"\n        alt=\"Open In Colab\"\n    \/>\n<\/a>\n\n<Tabs groupId=\"usedDatasets\" >\n<TabItem value=\"inputs\" label=\"inputs\">\n\n-   `df['embedding']` contain the [embeddings](..\/glossary\/index.mdx#embedding) for each data sample\n\n<\/TabItem>\n<TabItem value=\"outputs\" label=\"outputs\">\n\n-   `df['nn_id']` contains the sample id for the [nearest neighbor](..\/glossary\/index.mdx#nearest-neighbor) in the embedding space.\n-   `df['nn_image']` contains the path to the [image](..\/glossary\/index.mdx#image-data) that is the nearest neighbor.\n-   `df['nn_distance']` contains distance to the nearest neighbor.\n-   `df['nn_flag']` contains a flag that indicates if the sample is a near-duplicate according to the given threshold.\n\n<\/TabItem>\n<TabItem value=\"parameters\" label=\"parameters\">\n* `threshold` denotes the distance threshold when a data sample is considered a near-duplicate.\n* `tree_size` is an internal parameter for the Annoy library that calibrates the speed-efficiency tradeoff. More trees gives higher precision when querying.\n<\/TabItem>\n<\/Tabs>\n\n![Spotlight_screenshot_decision_boundary](\/playbook\/duplicates_annoy_screenshot.png)\n\n## Imports and play as copy-n-paste functions\n\n<details>\n    <summary># Install dependencies<\/summary>\n\n```python\n#@title Install required packages with PIP\n\n!pip install renumics-spotlight datasets annoy\n```\n\n<\/details>\n\n<details>\n    <summary># Play as copy-n-paste functions<\/summary>\n\n```python\n#@title Play as copy-n-paste functions\n\nimport datasets\nfrom renumics import spotlight\nfrom annoy import AnnoyIndex\nimport pandas as pd\nimport requests\n\n\ndef nearest_neighbor_annoy(df, embedding_name='embedding', threshold=0.3, tree_size=100):\n\n    embs = df[embedding_name]\n\n    t = AnnoyIndex(len(embs[0]), 'angular')\n\n    for idx, x in enumerate(embs):\n          t.add_item(idx, x)\n\n    t.build(tree_size)\n\n    images = df['image']\n\n    df_nn = pd.DataFrame()\n\n    nn_id = [t.get_nns_by_item(i,2)[1] for i in range(len(embs))]\n    df_nn['nn_id'] = nn_id\n    df_nn['nn_image'] = [images[i] for i in nn_id]\n    df_nn['nn_distance'] = [t.get_distance(i, nn_id[i]) for i in range(len(embs))]\n    df_nn['nn_flag'] = (df_nn.nn_distance < threshold)\n\n\n    return df_nn\n```\n\n<\/details>\n\n## Step-by-step example on CIFAR-100\n\n### Load CIFAR-100 from Huggingface hub and convert it to Pandas dataframe\n\n```python\ndataset = datasets.load_dataset(\"renumics\/cifar100-enriched\", split=\"train\")\ndf = dataset.to_pandas()\n```\n\n### Compute nearest neighbors including distances\n\n```python\ndf_nn = nearest_neighbor_annoy(df)\ndf = pd.concat([df, df_nn], axis=1)\n```\n\n### Inspect and remove duplicates with Spotlight\n\n```python\ndf_show = df.drop(columns=['embedding', 'probabilities'])\nlayout_url = \"https:\/\/raw.githubusercontent.com\/Renumics\/spotlight\/playbook_initial_draft\/playbook\/rookie\/duplicates_annoy.json\"\nresponse = requests.get(layout_url)\nlayout = spotlight.layout.nodes.Layout(**json.loads(response.text))\nspotlight.show(df_show, dtype={\"image\": spotlight.Image, \"embedding_reduced\": spotlight.Embedding}, layout=layout)\n```","---\ntags: []\nid: text-classification\nslug: \/docs\/use-cases\/text-classification\n---\n\n# Detect Problems in Text Classification Datasets\n\nUse the [**sliceguard**](https:\/\/github.com\/Renumics\/sliceguard) library and [**Spotlight**](https:\/\/github.com\/Renumics\/spotlight) to quickly **detect problem clusters** that can cause issues when training your text classification model. Shows problems such as:\n\n1. Label Inconsistencies\n2. Outliers and Errors\n3. Text-specific Issues (e.g. typos, empty samples)\n\nGenerally it will show you everything that is hard to learn for a classification model. All you need is a dataframe containing **texts** and **labels**.\n\nFirst install the dependencies:\n\n```\npip install renumics-spotlight sliceguard[all] scikit-learn\n```\n\nThen run the following code to detect problematic clusters:\n\n```python\n# The Imports\nfrom renumics import spotlight\nfrom sliceguard import SliceGuard\nfrom sliceguard.data import from_huggingface\nfrom sklearn.metrics import accuracy_score\n\n# Load an Example Dataset as DataFrame\ndf = from_huggingface(\"dair-ai\/emotion\")\n\n# DataFrame Format:\n# +-------+-------+\n# | text  | label |\n# +-------+-------+\n# | text1 | joy   |\n# | text2 | anger |\n# | text3 | joy   |\n# | ...   |       |\n# +-------+-------+\n\n# Detect Issues Using sliceguard\nsg = SliceGuard()\nissues = sg.find_issues(df, features=[\"text\"], y=\"label\", metric=accuracy_score)\nreport_df, spotlight_data_issues, spotlight_dtypes, spotlight_layout = sg.report(\n    no_browser=True\n)\n\n# Visualize Detected Issues in Spotlight:\nspotlight.show(\n    report_df,\n    dtype=spotlight_dtypes,\n    issues=spotlight_data_issues,\n    layout=spotlight_layout,\n)\n```","---\ntitle: \ud83e\udd17 Loading Huggingface Data\nslug: \/docs\/loading-data\/huggingface\nsidebar_position: 30\n---\n\n# Loading Data from Huggingface datasets\n\n![Huggingface example](\/img\/speech_commands_vis_s.gif)\n\nThe Hugging Face datasets library not only provides access to more than 70k publicly available datasets, but also offers very convenient data preparation pipelines for custom datasets.\n\nRenumics Spotlight allows you to create interactive visualizations to identify critical clusters in your data. Because Spotlight understands the data semantics within Hugging Face datasets, you can get started with just one line of code:\n\n```python\nimport datasets\nfrom renumics import spotlight\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='validation')\n\nspotlight.show(ds)\n```\n\n## Spotlight \ud83e\udd1d Hugging Face datasets\n\nThe datasets library has several features that makes it an ideal tool for working with ML datasets: It stores tabular data (e.g. metadata, labels) along with unstructured data (e.g. images, audio) in a common Arrows table. Datasets also describes important data semantics through features (e.g. images, audio) and additional task-specific metadata.\n\nSpotlight directly works on top of the datasets library. This means that there is no need to copy or pre-process the dataset for data visualization and inspection. Spotlight loads the tabular data into memory to allow for efficient, client-side data analytics. Memory-intensive unstructured data samples (e.g. audio, images, video) are loaded lazily on demand. In most cases, data types and label mappings are inferred directly from the dataset. Here, we visualize the CIFAR-100 dataset with one line of code:\n\n```python\nds = datasets.load_dataset('cifar100', split='test')\nspotlight.show(ds)\n```\n\nIn cases where the data types are ambiguous or not specified, the Spotlight API allows to manually assign them:\n\n```python\nlabel_mapping = dict(zip(ds.features['fine_label'].names, range(len(ds.features['fine_label'].names))))\nspotlight.show(ds, dtype={'img': spotlight.Image, 'fine_label': spotlight.dtypes.CategoryDType(categories=label_mapping)})\n```\n\n## Supported data types\n\nMore details on the supported data types can be found in the [data types section](..\/loading-data#supported-data-types)\n\n## Detailed examples\n\nTake a look at our [use case section](..\/use-cases) to find more detailed examples for different modalities."],"3":["---\nsidebar_position: 30\nslug: \/docs\/configure-visualizations\n---\n\n# Configuring visualizations\n\nData inspection is critical for all steps in the ML development workflow. But it is also time consuming: First of all it takes effort to build and maintain custom visualization pipelines. Second of all, it takes time to sift through data manually.\n\nSpotlight enables you to build scalable data inspection workflows. With Spotlight you can\n\n-   Create visualizations for unstructured data with a single line of code\n-   Leverage model results to find relevant data segments quickly\n-   Create custom interaction templates for your team\n\nIn order to achieve this, the Spotlight UI provides a range of components that offer different perspectives on your data. You can add, remove, and rearrange these components as you wish to create a customized inspection layouts.\n\nOnce you have identified a component layout that works well for you, you can save it as a layout for future use. This way, you can quickly load your preferred layout whenever you need it, without having to reconfigure the UI each time.\n\n## UI components\n\nSpotlight includes the [Inspector](ui_components\/inspector_view.mdx) and the [Data Table](ui_components\/table_view.mdx) to help you in analyzing and understanding individual datapoints. Other visualization options like the [Similarity Map](ui_components\/similarity_map.mdx), the [Scatter Plot](ui_components\/scatter_plot.mdx) and the [Histogram](ui_components\/histogram.mdx) aide you to understand the overall distribution of your data.\n\nThe [Filter Bar](ui_components\/filter_bar.mdx) is a special component that allows you to filter your data based on the values of your features.<br\/>\nFiltering and selecting datapoints can affect how data is presented in the other components and therefore can greatly help you in analyzing and reasoning about your data.\n\nAn overview over all available components can be found in the [UI components](ui_components\/index.mdx) section.\n\n## Layout API\n\n## Issues widget","---\nsidebar_position: 40\nslug: \/docs\/configure-visualizations\/issues\n---\n\n# \ud83d\udd16 Defining data issues\n\nSpotlight allows to define highlight specific data clusters. These clusters can be defined by their respective row and\/or column ids an allow to quickly inspect critical issues in your data.","Leveraging model results such as predictions or embeddings can help to uncover critical data samples and clusters. In practice, these enrichments can be stored in a separate dataframe and then joined with the raw dataset. Here is an example from the Huggingface hub:\n\n```python\nimport datasets\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='all')\nds_results = datasets.load_dataset('renumics\/speech_commands-ast-finetuned-results', 'v0.01', split='all')\nds = datasets.concatenate_datasets([ds, ds_results], axis=1)\n```\n\nDepending on the task at hand (e.g. EDA, model debugging, monitoring), you probably want to set up a suitable visualization layout. You can do so in the GUI and via API. We also ship starter layouts for common tasks that you can use out of the box:\n\n```python\nfrom renumics import spotlight\n\nlayout = spotlight.layouts.debug_classification(embedding='embedding', inspect={'audio': spotlight.dtypes.audio_dtype})\nspotlight.show(ds, dtype={'embedding': spotlight.Embedding}, layout=layout )\n```\n\n## Disclaimer\n\n<details>\n    <summary>Usage Tracking<\/summary>\n\nWe have added crash report and perfomance collection.<br \/>\n**We do NOT** collect user data other than an **anonymized Machine Id** obtained by py-machineid, and only log our own actions.<br \/>\n**We do NOT** collect folder names, dataset names, or row data of any kind only aggregate performance statistics like total time of a table_load, crash data, etc.<br \/>\nCollecting spotlight crashes will help us improve stability.<br \/>\n\n<br \/>\n<br \/>\nToo opt out of the crash report collection define an environment variable called\nSPOTLIGHT_OPT_OUT and set it to true.\n\ne.G.\n\n```bash\nexport SPOTLIGHT_OPT_OUT=true\n```\n\n<\/details>"],"4":["---\ntags: []\nid: audio-classification\nslug: \/docs\/use-cases\/audio-classification\n---\n\n# Detect Problems in Audio Classification Datasets\n\nUse the [**sliceguard**](https:\/\/github.com\/Renumics\/sliceguard) library and [**Spotlight**](https:\/\/github.com\/Renumics\/spotlight) to quickly **detect problem clusters** that can cause issues when training your audio classification model. Shows problems such as:\n\n1. Label Inconsistencies\n2. Outliers and Errors\n3. Audio-specific Issues (e.g. clipping)\n\nGenerally it will show you everything that is hard to learn for a classification model. All you need is a dataframe containing **paths to audio files** and **labels**.\n\nFirst install the dependencies:\n\n```\npip install renumics-spotlight sliceguard[all] scikit-learn\n```\n\nThen run the following code to detect problematic clusters:\n\n```python\n# The Imports\nfrom renumics import spotlight\nfrom sliceguard import SliceGuard\nfrom sliceguard.data import from_huggingface\nfrom sklearn.metrics import accuracy_score\n\n# Load an Example Dataset as DataFrame\ndf = from_huggingface(\"renumics\/emodb\")\n\n# DataFrame Format:\n# +---------------------+---------+\n# |        audio        | emotion |\n# +---------------------+---------+\n# | \/path\/to\/audio1.wav | joy     |\n# | \/path\/to\/audio2.wav | anger   |\n# | \/path\/to\/audio3.wav | joy     |\n# | ...                 |         |\n# +---------------------+---------+\n\n# Detect Issues Using sliceguard\nsg = SliceGuard()\nissues = sg.find_issues(df, features=[\"audio\"], y=\"emotion\", metric=accuracy_score)\nreport_df, spotlight_data_issues, spotlight_dtypes, spotlight_layout = sg.report(\n    no_browser=True\n)\n\n# Visualize Detected Issues in Spotlight:\nspotlight.show(\n    report_df,\n    dtype=spotlight_dtypes,\n    issues=spotlight_data_issues,\n    layout=spotlight_layout,\n)\n\n```","<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/image-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/image-view-512.jpg\"\n    annotation=\"_mnist_ - display and zoom\/pan images in a **Image** view\"\n\/>\n\n### Audio data\n\n**Audio data** can be represented with an _Audio Player_ or a _Spectrogram_. The _Audio Player_ supports annotating event windows in the data.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/audio-window-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/audio-window-view-512.jpg\"\n    annotation=\"_fsd50k_ - display and control audio with\/without an additional window\"\n\/>\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/audio-window-edit-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/audio-window-edit-view-512.jpg\"\n    annotation=\"_fsd50k_ - edit audio window\"\n\/>\n\n### Video data\n\n**Video data** can be represented with an _Video Player_.\n\n### 3D Meshes\n\n**3D meshes** can be represented by a _Mesh Viewer_. This components supports surface coloring to display mesh properties (e.g. stresses) and animated meshes.\n\n### Boolean data\n\n**Boolean data** can be represented by a _Switch_ element to facilitate efficient data annotation and tagging.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/bool-switch-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/bool-switch-view-512.jpg\"\n    annotation=\"_fsd50k_ - edit bool values in **Switch** view\"\n\/>","---\ntags: []\nid: cv-issues\nsidebar_position: 85\nslug: \/docs\/data-centric-ai\/playbook\/cv-issues\n---\n\nimport Tabs from \"@theme\/Tabs\";\nimport TabItem from \"@theme\/TabItem\";\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Find typical issues in image datasets with Cleanvision\n\nWe extract typical issues (regarding brightness, blurr, aspect ratio, SNR and duplicates) in image datasets with the [Cleanvision library](https:\/\/github.com\/cleanlab\/cleanvision). We then identify critical segments with Spotlight.\n\n> Use Chrome to run Spotlight in Colab. Due to Colab restrictions (e.g. no websocket support), the performance is limited. Run the notebook locally for the full Spotlight experience.\n\n<a\n    target=\"_blank\"\n    href=\"https:\/\/colab.research.google.com\/github\/Renumics\/spotlight\/blob\/main\/playbook\/veteran\/cv_issues.ipynb\"\n>\n    <img\n        src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\"\n        alt=\"Open In Colab\"\n    \/>\n<\/a>\n\n<Tabs groupId=\"usedDatasets\" >\n<TabItem value=\"inputs\" label=\"inputs\">\n\n-   `df['image']` contains the paths to the [images](..\/glossary\/index.mdx#image-data) in the dataset\n\n<\/TabItem>\n<TabItem value=\"outputs\" label=\"outputs\">\n\n-   `df['dark_score']` contains a score [0,1] that denotes the [darkness](..\/glossary\/index.mdx#darkness) of the image sample.\n-   `df['light_score']` contains a score [0,1] that denotes the [lightness](..\/glossary\/index.mdx#lightness) of the image sample.\n-   `df['blurry_score']` contains a score [0,1] that denotes the [blurriness](..\/glossary\/index.mdx#blurriness) of the image sample.\n-   `df['low_information_score']` contains a score [0,1] that denotes the [Signal-to-Noise ratio](..\/glossary\/index.mdx#signal-to-noise-ratio) of the image sample.\n-   `df['odd_aspect_ratio_score']` contains a score [0,1] that denotes anomalies in the [aspect ratio](..\/glossary\/index.mdx#aspect-ratio) of the image sample.\n\n<\/TabItem>\n<TabItem value=\"parameters\" label=\"parameters\">\n\n<\/TabItem>\n<\/Tabs>\n\n![Spotlight_screenshot_outliers](\/playbook\/outlier_cleanlab_screenshot.png)\n\n## Imports and play as copy-n-paste functions\n\n<details>\n    <summary># Install dependencies<\/summary>\n\n```python\n#@title Install required packages with PIP\n\n!pip install renumics-spotlight cleanlab datasets\n```\n\n<\/details>\n\n<details>\n    <summary># Play as copy-n-paste functions<\/summary>\n\n```python\n#@title Play as copy-n-paste functions\n\nfrom cleanvision.imagelab import Imagelab\nimport pandas as pd\nfrom renumics import spotlight\nimport requests\n\ndef cv_issues_cleanvision(df, image_name='image'):\n\n    image_paths = df['image'].to_list()\n    imagelab = Imagelab(filepaths=image_paths)\n    imagelab.find_issues()\n\n    df_cv=imagelab.issues.reset_index()\n\n    return df_cv\n```\n\n<\/details>\n\n## Step-by-step example on CIFAR-100\n\n### Load CIFAR-100 from Huggingface hub and convert it to Pandas dataframe\n\n```python\ndataset = datasets.load_dataset(\"renumics\/cifar100-enriched\", split=\"train\")\ndf = dataset.to_pandas()\n```\n\n### Compute heuristics for typical image data error scores with Cleanvision\n\n```python\ndf_cv=cv_issues_cleanvision(df)\ndf = pd.concat([df, df_cv], axis=1)\n```\n\n### Inspect errors and detect problematic data segments with Spotlight\n\n```python\ndf_show = df.drop(columns=['embedding', 'probabilities'])\nlayout_url = \"https:\/\/raw.githubusercontent.com\/Renumics\/spotlight\/playbook_initial_draft\/playbook\/rookie\/cv_issues.json\"\nresponse = requests.get(layout_url)\nlayout = spotlight.layout.nodes.Layout(**json.loads(response.text))\nspotlight.show(df_show, dtype={\"image\": spotlight.Image, \"embedding_reduced\": spotlight.Embedding}, layout=layout)\n```"],"5":["---\nsidebar_position: 30\nslug: \/docs\/configure-visualizations\n---\n\n# Configuring visualizations\n\nData inspection is critical for all steps in the ML development workflow. But it is also time consuming: First of all it takes effort to build and maintain custom visualization pipelines. Second of all, it takes time to sift through data manually.\n\nSpotlight enables you to build scalable data inspection workflows. With Spotlight you can\n\n-   Create visualizations for unstructured data with a single line of code\n-   Leverage model results to find relevant data segments quickly\n-   Create custom interaction templates for your team\n\nIn order to achieve this, the Spotlight UI provides a range of components that offer different perspectives on your data. You can add, remove, and rearrange these components as you wish to create a customized inspection layouts.\n\nOnce you have identified a component layout that works well for you, you can save it as a layout for future use. This way, you can quickly load your preferred layout whenever you need it, without having to reconfigure the UI each time.\n\n## UI components\n\nSpotlight includes the [Inspector](ui_components\/inspector_view.mdx) and the [Data Table](ui_components\/table_view.mdx) to help you in analyzing and understanding individual datapoints. Other visualization options like the [Similarity Map](ui_components\/similarity_map.mdx), the [Scatter Plot](ui_components\/scatter_plot.mdx) and the [Histogram](ui_components\/histogram.mdx) aide you to understand the overall distribution of your data.\n\nThe [Filter Bar](ui_components\/filter_bar.mdx) is a special component that allows you to filter your data based on the values of your features.<br\/>\nFiltering and selecting datapoints can affect how data is presented in the other components and therefore can greatly help you in analyzing and reasoning about your data.\n\nAn overview over all available components can be found in the [UI components](ui_components\/index.mdx) section.\n\n## Layout API\n\n## Issues widget","---\ntags: []\nid: inspector\nsidebar_position: 20\nslug: \/docs\/custom-visualizations\/ui-components\/inspector\n---\n\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Inspector\n\nThe Inspector Widget is a component in Spotlight that lets you examine and edit the features of **individual data points** in your dataset.\nWith its multiple views for **different modalities**, the Inspector Widget provides a detailed look at a data point's underlying structure.\n\nThe Inspector Widget's views for text, audio, video, and 3D geometry data allow you to explore a data point's features in depth.\nYou can also edit those features directly within the view, making it easy to make changes to a data point without navigating to a separate screen.\nThe Inspector Widget is an essential tool for working with multimodal datasets and gives you greater control over the structure and quality of your data.\n\n:::info\n\nThe open source version of Renumics Spotlight allows you to inspect your data to find critical segments. The Pro version of Spotlight also enables data tagging and annotation.\n\n:::\n\nBy configuring the inspector view you can choose how each datapoint should be represented. The main configuration options are available in the upper right corner of the view:\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/inspector-view-overview\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720, 1280]}\n    annotation=\"_fsd50k_ - add and layout components in the **Inspector View**\"\n\/>\n\nThere are visualization and interaction components available for many different data types. These include:\n\n### Text data\n\n**Text data** can be represented either with a **Value** view or a **Select** view that features autocomplete.\n\n<!-- poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\/text-value-field.jpg\" -->\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field-512.jpg\"\n    annotation=\"_fsd50k_ - display annotation in a **Value** view\"\n\/>\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field.jpg\"\n    annotation=\"_fsd50k_ - display and update annotation in a **Select** view\"\n\/>\n\n### Categorical data\n\n**Categorical data** is represented similarly to **Text data** with the exception, that when there are not too many categories, they can also be edited with a switch component.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field-512.jpg\"\n    annotation=\"_mnist_ - display and update categories in a **Switch** view\"\n\/>\n\n### Image data\n\n**Image data** can be represented with an imager viewer that supports zooming and panning.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/image-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/image-view-512.jpg\"\n    annotation=\"_mnist_ - display and zoom\/pan images in a **Image** view\"\n\/>\n\n### Audio data\n\n**Audio data** can be represented with an _Audio Player_ or a _Spectrogram_. The _Audio Player_ supports annotating event windows in the data.","`inspector(name=None, lenses=None, num_columns=4)` {inspector()}\n\nAdd an inspector widget with optionally preconfigured viewers (lenses).\n\n Example\n\n```python\n>>> from renumics.spotlight import layout\n>>> from renumics.spotlight.layout import lenses\n>>> spotlight_layout = layout.layout(\n...     layout.inspector(\n...         \"My Inspector\",\n...         [\n...             lenses.scalar(\"bool\"),\n...             lenses.scalar(\"float\"),\n...             lenses.scalar(\"str\"),\n...             lenses.scalar(\"datetime\"),\n...             lenses.scalar(\"category\"),\n...             lenses.scalar(\"int\"),\n...             lenses.text(\"str\", name=\"text\"),\n...             lenses.html(\"str\", name=\"HTML (safe)\"),\n...             lenses.html(\"str\", name=\"HTML\", unsafe=True),\n...             lenses.markdown(\"str\", name=\"MD\"),\n...             lenses.array(\"embedding\"),\n...             lenses.array(\"window\"),\n...             lenses.array(\"array\"),\n...             lenses.sequences(\"sequence\"),\n...             lenses.sequences([\"sequence1\", \"sequence2\"], name=\"sequences\"),\n...             lenses.mesh(\"mesh\"),\n...             lenses.image(\"image\"),\n...             lenses.video(\"video\"),\n...             lenses.audio(\"audio\"),\n...             lenses.audio(\"audio\", window_column=\"window\", name=\"windowed audio\"),\n...             lenses.spectrogram(\"audio\"),\n...             lenses.spectrogram(\n...                 \"audio\",\n...                 window_column=\"window\",\n...                 name=\"windowed spectrogram\",\n...             ),\n...         ],\n...         num_columns=2,\n...     )\n... )\n```"],"6":["---\ntags: []\nid: inspector\nsidebar_position: 20\nslug: \/docs\/custom-visualizations\/ui-components\/inspector\n---\n\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Inspector\n\nThe Inspector Widget is a component in Spotlight that lets you examine and edit the features of **individual data points** in your dataset.\nWith its multiple views for **different modalities**, the Inspector Widget provides a detailed look at a data point's underlying structure.\n\nThe Inspector Widget's views for text, audio, video, and 3D geometry data allow you to explore a data point's features in depth.\nYou can also edit those features directly within the view, making it easy to make changes to a data point without navigating to a separate screen.\nThe Inspector Widget is an essential tool for working with multimodal datasets and gives you greater control over the structure and quality of your data.\n\n:::info\n\nThe open source version of Renumics Spotlight allows you to inspect your data to find critical segments. The Pro version of Spotlight also enables data tagging and annotation.\n\n:::\n\nBy configuring the inspector view you can choose how each datapoint should be represented. The main configuration options are available in the upper right corner of the view:\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/inspector-view-overview\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720, 1280]}\n    annotation=\"_fsd50k_ - add and layout components in the **Inspector View**\"\n\/>\n\nThere are visualization and interaction components available for many different data types. These include:\n\n### Text data\n\n**Text data** can be represented either with a **Value** view or a **Select** view that features autocomplete.\n\n<!-- poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\/text-value-field.jpg\" -->\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field-512.jpg\"\n    annotation=\"_fsd50k_ - display annotation in a **Value** view\"\n\/>\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field.jpg\"\n    annotation=\"_fsd50k_ - display and update annotation in a **Select** view\"\n\/>\n\n### Categorical data\n\n**Categorical data** is represented similarly to **Text data** with the exception, that when there are not too many categories, they can also be edited with a switch component.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field-512.jpg\"\n    annotation=\"_mnist_ - display and update categories in a **Switch** view\"\n\/>\n\n### Image data\n\n**Image data** can be represented with an imager viewer that supports zooming and panning.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/image-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/image-view-512.jpg\"\n    annotation=\"_mnist_ - display and zoom\/pan images in a **Image** view\"\n\/>\n\n### Audio data\n\n**Audio data** can be represented with an _Audio Player_ or a _Spectrogram_. The _Audio Player_ supports annotating event windows in the data.","`inspector(name=None, lenses=None, num_columns=4)` {inspector()}\n\nAdd an inspector widget with optionally preconfigured viewers (lenses).\n\n Example\n\n```python\n>>> from renumics.spotlight import layout\n>>> from renumics.spotlight.layout import lenses\n>>> spotlight_layout = layout.layout(\n...     layout.inspector(\n...         \"My Inspector\",\n...         [\n...             lenses.scalar(\"bool\"),\n...             lenses.scalar(\"float\"),\n...             lenses.scalar(\"str\"),\n...             lenses.scalar(\"datetime\"),\n...             lenses.scalar(\"category\"),\n...             lenses.scalar(\"int\"),\n...             lenses.text(\"str\", name=\"text\"),\n...             lenses.html(\"str\", name=\"HTML (safe)\"),\n...             lenses.html(\"str\", name=\"HTML\", unsafe=True),\n...             lenses.markdown(\"str\", name=\"MD\"),\n...             lenses.array(\"embedding\"),\n...             lenses.array(\"window\"),\n...             lenses.array(\"array\"),\n...             lenses.sequences(\"sequence\"),\n...             lenses.sequences([\"sequence1\", \"sequence2\"], name=\"sequences\"),\n...             lenses.mesh(\"mesh\"),\n...             lenses.image(\"image\"),\n...             lenses.video(\"video\"),\n...             lenses.audio(\"audio\"),\n...             lenses.audio(\"audio\", window_column=\"window\", name=\"windowed audio\"),\n...             lenses.spectrogram(\"audio\"),\n...             lenses.spectrogram(\n...                 \"audio\",\n...                 window_column=\"window\",\n...                 name=\"windowed spectrogram\",\n...             ),\n...         ],\n...         num_columns=2,\n...     )\n... )\n```","---\nsidebar_position: 30\nslug: \/docs\/configure-visualizations\n---\n\n# Configuring visualizations\n\nData inspection is critical for all steps in the ML development workflow. But it is also time consuming: First of all it takes effort to build and maintain custom visualization pipelines. Second of all, it takes time to sift through data manually.\n\nSpotlight enables you to build scalable data inspection workflows. With Spotlight you can\n\n-   Create visualizations for unstructured data with a single line of code\n-   Leverage model results to find relevant data segments quickly\n-   Create custom interaction templates for your team\n\nIn order to achieve this, the Spotlight UI provides a range of components that offer different perspectives on your data. You can add, remove, and rearrange these components as you wish to create a customized inspection layouts.\n\nOnce you have identified a component layout that works well for you, you can save it as a layout for future use. This way, you can quickly load your preferred layout whenever you need it, without having to reconfigure the UI each time.\n\n## UI components\n\nSpotlight includes the [Inspector](ui_components\/inspector_view.mdx) and the [Data Table](ui_components\/table_view.mdx) to help you in analyzing and understanding individual datapoints. Other visualization options like the [Similarity Map](ui_components\/similarity_map.mdx), the [Scatter Plot](ui_components\/scatter_plot.mdx) and the [Histogram](ui_components\/histogram.mdx) aide you to understand the overall distribution of your data.\n\nThe [Filter Bar](ui_components\/filter_bar.mdx) is a special component that allows you to filter your data based on the values of your features.<br\/>\nFiltering and selecting datapoints can affect how data is presented in the other components and therefore can greatly help you in analyzing and reasoning about your data.\n\nAn overview over all available components can be found in the [UI components](ui_components\/index.mdx) section.\n\n## Layout API\n\n## Issues widget"],"7":["---\ntags: []\nid: sliceguard\nsidebar_position: 6055\nslug: \/docs\/data-centric-ai\/playbook\/data-slices-sliceguard\n---\n\nimport Tabs from \"@theme\/Tabs\";\nimport TabItem from \"@theme\/TabItem\";\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Find data slices with Sliceguard\n\nWe use [Sliceguard](https:\/\/github.com\/Renumics\/sliceguard) to identify data segments where our machine learning model performs anomalously (data slices). We interactively explore these data slices to find model failure modes and problematic data segments.\n\n> Use Chrome to run Spotlight in Colab. Due to Colab restrictions (e.g. no websocket support), the performance is limited. Run the notebook locally for the full Spotlight experience.\n\n<a\n    target=\"_blank\"\n    href=\"https:\/\/colab.research.google.com\/github\/Renumics\/spotlight\/blob\/main\/playbook\/allstar\/data-slices-sliceguard.ipynb\"\n>\n    <img\n        src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\"\n        alt=\"Open In Colab\"\n    \/>\n<\/a>\n\n<Tabs groupId=\"usedDatasets\" >\n<TabItem value=\"inputs\" label=\"inputs\">\n\n-   `categories` contains contain the names of the [features](..\/glossary\/index.mdx#features) and [metadata](..\/glossary\/index.mdx#metadata) columns that are to be analyzed\n-   `df['label']` contains the [label](..\/glossary\/index.mdx#label) for each data sample\n-   `df['prediction']` contains the [prediction](..\/glossary\/index.mdx#label) for each data sample\n-   `df['embedding']` contains the [embeddings](..\/glossary\/index.mdx#embedding) for each data sample (optional)\n\n<\/TabItem>\n\n<TabItem value=\"outputs\" label=\"outputs\">\n\n-   `df_slices contains a dataframe with a description of the issues found\n\n<\/TabItem>\n\n<TabItem value=\"parameters\" label=\"parameters\">\n* `category_types` (optional) describes the type of the features and metadata (\"raw\", \"nominal\", \"ordinal\", \"numerical\", \"embedding\").\n* `spotlight_dtype` (optional) describes data types for the visualization with Spotlight.\n<\/TabItem>\n<\/Tabs>\n\n![Spotlight_screenshot_drift_kcore](\/playbook\/screenshot_sliceguard.png)\n\n## Imports and play as copy-n-paste functions\n\n<details>\n    <summary># Install dependencies<\/summary>\n\n```python\n#@title Install required packages with PIP\n\n!pip install renumics-spotlight sliceguard datasets cleanvision\n```\n\n<\/details>\n\n<details>\n    <summary>Play as copy-n-paste functions<\/summary>\n\n```python\n#@title Play as copy-n-paste snippet\n\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport datasets\nfrom renumics.spotlight import Image\nfrom sliceguard import SliceGuard\nfrom cleanvision.imagelab import Imagelab","def find_data_slices(df, categories, category_types={}, spotlight_dtype={}, embedding_name='embedding', label_name='label', prediction_name='prediction'):\n    sg = SliceGuard()\n    df_slices = sg.find_issues(\n        df,\n        categories,\n        label_name,\n        prediction_name,\n        accuracy_score,\n        precomputed_embeddings = {'embedding': df[embedding_name].to_numpy()},\n        metric_mode=\"max\",\n        feature_types=category_types\n    )\n\n    sg.report(spotlight_dtype=spotlight_dtype)\n\n    return df_slices\n```\n\n<\/details>\n\n## Step-by-step example on CIFAR-100\n\n### Load CIFAR-100 from Huggingface hub and convert it to Pandas dataframe\n\n```python\ndataset = datasets.load_dataset(\"renumics\/cifar100-enriched\", split=\"test\")\ndf = dataset.to_pandas()\n```\n\n### Enrich dataset with metadata using [Cleanvision](.\/cv_issues.mdx)\n\n```python\ndef cv_issues_cleanvision(df, image_name='image'):\n\n    image_paths = df['image'].to_list()\n    imagelab = Imagelab(filepaths=image_paths)\n    imagelab.find_issues()\n\n    df_cv=imagelab.issues.reset_index()\n\n    return df_cv\n\ndf_cv = cv_issues_cleanvision(df)\ndf = pd.concat([df, df_cv], axis=1)\n```\n\n### Identify and explore data slices with Sliceguard\n\n```python\ncategories=['dark_score', 'low_information_score', 'light_score', 'blurry_score', 'fine_label']\nprediction = 'fine_label_prediction'\nlabel = 'fine_label'\ncategory_types={'fine_label': 'nominal'}\nspotlight_dtype={\"image\": Image}\n\nfind_data_slices(df, categories, category_types=category_types, spotlight_dtype=spotlight_dtype, embedding_name='embedding', label_name=label, prediction_name=prediction)\n\n```","---\ntags: []\nid: text-classification\nslug: \/docs\/use-cases\/text-classification\n---\n\n# Detect Problems in Text Classification Datasets\n\nUse the [**sliceguard**](https:\/\/github.com\/Renumics\/sliceguard) library and [**Spotlight**](https:\/\/github.com\/Renumics\/spotlight) to quickly **detect problem clusters** that can cause issues when training your text classification model. Shows problems such as:\n\n1. Label Inconsistencies\n2. Outliers and Errors\n3. Text-specific Issues (e.g. typos, empty samples)\n\nGenerally it will show you everything that is hard to learn for a classification model. All you need is a dataframe containing **texts** and **labels**.\n\nFirst install the dependencies:\n\n```\npip install renumics-spotlight sliceguard[all] scikit-learn\n```\n\nThen run the following code to detect problematic clusters:\n\n```python\n# The Imports\nfrom renumics import spotlight\nfrom sliceguard import SliceGuard\nfrom sliceguard.data import from_huggingface\nfrom sklearn.metrics import accuracy_score\n\n# Load an Example Dataset as DataFrame\ndf = from_huggingface(\"dair-ai\/emotion\")\n\n# DataFrame Format:\n# +-------+-------+\n# | text  | label |\n# +-------+-------+\n# | text1 | joy   |\n# | text2 | anger |\n# | text3 | joy   |\n# | ...   |       |\n# +-------+-------+\n\n# Detect Issues Using sliceguard\nsg = SliceGuard()\nissues = sg.find_issues(df, features=[\"text\"], y=\"label\", metric=accuracy_score)\nreport_df, spotlight_data_issues, spotlight_dtypes, spotlight_layout = sg.report(\n    no_browser=True\n)\n\n# Visualize Detected Issues in Spotlight:\nspotlight.show(\n    report_df,\n    dtype=spotlight_dtypes,\n    issues=spotlight_data_issues,\n    layout=spotlight_layout,\n)\n```"],"8":["`audio(column, window_column=None, name=None, *, repeat=False, autoplay=False)` {audio()}\n\nAdd audio viewer to Spotlight inspector widget.\n\nSupports a single column of type `spotlight.Audio` with optional second\ncolumn of type `spotlight.Window`.","---\ntags: []\nid: inspector\nsidebar_position: 20\nslug: \/docs\/custom-visualizations\/ui-components\/inspector\n---\n\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Inspector\n\nThe Inspector Widget is a component in Spotlight that lets you examine and edit the features of **individual data points** in your dataset.\nWith its multiple views for **different modalities**, the Inspector Widget provides a detailed look at a data point's underlying structure.\n\nThe Inspector Widget's views for text, audio, video, and 3D geometry data allow you to explore a data point's features in depth.\nYou can also edit those features directly within the view, making it easy to make changes to a data point without navigating to a separate screen.\nThe Inspector Widget is an essential tool for working with multimodal datasets and gives you greater control over the structure and quality of your data.\n\n:::info\n\nThe open source version of Renumics Spotlight allows you to inspect your data to find critical segments. The Pro version of Spotlight also enables data tagging and annotation.\n\n:::\n\nBy configuring the inspector view you can choose how each datapoint should be represented. The main configuration options are available in the upper right corner of the view:\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/inspector-view-overview\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720, 1280]}\n    annotation=\"_fsd50k_ - add and layout components in the **Inspector View**\"\n\/>\n\nThere are visualization and interaction components available for many different data types. These include:\n\n### Text data\n\n**Text data** can be represented either with a **Value** view or a **Select** view that features autocomplete.\n\n<!-- poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\/text-value-field.jpg\" -->\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field-512.jpg\"\n    annotation=\"_fsd50k_ - display annotation in a **Value** view\"\n\/>\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field.jpg\"\n    annotation=\"_fsd50k_ - display and update annotation in a **Select** view\"\n\/>\n\n### Categorical data\n\n**Categorical data** is represented similarly to **Text data** with the exception, that when there are not too many categories, they can also be edited with a switch component.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field-512.jpg\"\n    annotation=\"_mnist_ - display and update categories in a **Switch** view\"\n\/>\n\n### Image data\n\n**Image data** can be represented with an imager viewer that supports zooming and panning.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/image-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/image-view-512.jpg\"\n    annotation=\"_mnist_ - display and zoom\/pan images in a **Image** view\"\n\/>\n\n### Audio data\n\n**Audio data** can be represented with an _Audio Player_ or a _Spectrogram_. The _Audio Player_ supports annotating event windows in the data.","`spectrogram(column, window_column=None, name=None, *, frequency_scale='linear', amplitude_scale='decibel')` {spectrogram()}\n\nAdd audio spectrogram viewer to Spotlight inspector widget.\n\nSupports a single column of type `spotlight.Audio` with optional second\ncolumn of type `spotlight.Window`."],"9":["---\ntags: []\nid: inspector\nsidebar_position: 20\nslug: \/docs\/custom-visualizations\/ui-components\/inspector\n---\n\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Inspector\n\nThe Inspector Widget is a component in Spotlight that lets you examine and edit the features of **individual data points** in your dataset.\nWith its multiple views for **different modalities**, the Inspector Widget provides a detailed look at a data point's underlying structure.\n\nThe Inspector Widget's views for text, audio, video, and 3D geometry data allow you to explore a data point's features in depth.\nYou can also edit those features directly within the view, making it easy to make changes to a data point without navigating to a separate screen.\nThe Inspector Widget is an essential tool for working with multimodal datasets and gives you greater control over the structure and quality of your data.\n\n:::info\n\nThe open source version of Renumics Spotlight allows you to inspect your data to find critical segments. The Pro version of Spotlight also enables data tagging and annotation.\n\n:::\n\nBy configuring the inspector view you can choose how each datapoint should be represented. The main configuration options are available in the upper right corner of the view:\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/inspector-view-overview\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720, 1280]}\n    annotation=\"_fsd50k_ - add and layout components in the **Inspector View**\"\n\/>\n\nThere are visualization and interaction components available for many different data types. These include:\n\n### Text data\n\n**Text data** can be represented either with a **Value** view or a **Select** view that features autocomplete.\n\n<!-- poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\/text-value-field.jpg\" -->\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-value-field-512.jpg\"\n    annotation=\"_fsd50k_ - display annotation in a **Value** view\"\n\/>\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/text-select-field.jpg\"\n    annotation=\"_fsd50k_ - display and update annotation in a **Select** view\"\n\/>\n\n### Categorical data\n\n**Categorical data** is represented similarly to **Text data** with the exception, that when there are not too many categories, they can also be edited with a switch component.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={true}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/category-switch-field-512.jpg\"\n    annotation=\"_mnist_ - display and update categories in a **Switch** view\"\n\/>\n\n### Image data\n\n**Image data** can be represented with an imager viewer that supports zooming and panning.\n\n<Video\n    className=\"pt-10\"\n    basePath=\"\/data\/docs\/ui-components\/inspector-view\/image-view\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512]}\n    isPro={false}\n    poster=\"\/data\/docs\/ui-components\/inspector-view\/image-view-512.jpg\"\n    annotation=\"_mnist_ - display and zoom\/pan images in a **Image** view\"\n\/>\n\n### Audio data\n\n**Audio data** can be represented with an _Audio Player_ or a _Spectrogram_. The _Audio Player_ supports annotating event windows in the data.","---\nsidebar_position: 30\nslug: \/docs\/configure-visualizations\n---\n\n# Configuring visualizations\n\nData inspection is critical for all steps in the ML development workflow. But it is also time consuming: First of all it takes effort to build and maintain custom visualization pipelines. Second of all, it takes time to sift through data manually.\n\nSpotlight enables you to build scalable data inspection workflows. With Spotlight you can\n\n-   Create visualizations for unstructured data with a single line of code\n-   Leverage model results to find relevant data segments quickly\n-   Create custom interaction templates for your team\n\nIn order to achieve this, the Spotlight UI provides a range of components that offer different perspectives on your data. You can add, remove, and rearrange these components as you wish to create a customized inspection layouts.\n\nOnce you have identified a component layout that works well for you, you can save it as a layout for future use. This way, you can quickly load your preferred layout whenever you need it, without having to reconfigure the UI each time.\n\n## UI components\n\nSpotlight includes the [Inspector](ui_components\/inspector_view.mdx) and the [Data Table](ui_components\/table_view.mdx) to help you in analyzing and understanding individual datapoints. Other visualization options like the [Similarity Map](ui_components\/similarity_map.mdx), the [Scatter Plot](ui_components\/scatter_plot.mdx) and the [Histogram](ui_components\/histogram.mdx) aide you to understand the overall distribution of your data.\n\nThe [Filter Bar](ui_components\/filter_bar.mdx) is a special component that allows you to filter your data based on the values of your features.<br\/>\nFiltering and selecting datapoints can affect how data is presented in the other components and therefore can greatly help you in analyzing and reasoning about your data.\n\nAn overview over all available components can be found in the [UI components](ui_components\/index.mdx) section.\n\n## Layout API\n\n## Issues widget","---\ntags: []\nid: layout\nsidebar_position: 10\nslug: \/docs\/custom-visualizations\/ui-components\/layout\n---\n\nimport Video from \"@site\/src\/components\/DocsVideo\";\n\n# Layout\n\nSpotlights layout system works similar to the layout in normal desktop applications.<br \/>\nYou can add or remove widgets, rename them, move them around, resize and stack them.\n\nIf you find a layout that fits your needs you can easily save it and load it later.\n\n## Add and Delete Widget\n\nWidgets can easily be added to an existing Tab group by clicking on the + button in the top of the Tab group.\nTo delete a Widget click on the x button in the top of the Widget.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/layout\/add-delete-widget\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_\"\n\/>\n\n## Resize Widgets\n\nTo resize a widget simply drag the widgets border and move it to the desired size.\nBy clicking on the maximize\/minimize button a widget can be put to fullscreen mode and vice versa.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/layout\/resize-widget\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_\"\n\/>\n\n## Move and Stack Widgets\n\nTo move a widget simply drag the widgets title bar and move it to the desired position.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/layout\/move-widget\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_\"\n\/>\n\n## Rename Widgets\n\nIn order to rename a widget simply double-click on the widgets title bar and type in the new name.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/layout\/rename-widget\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_\"\n\/>\n\n## Save, Load and Reset the Layout\n\nLayouts can easily be saved, loaded or resetted by clicking on the layout button in the top right corner of the window.\n\n<Video\n    basePath=\"\/data\/docs\/ui-components\/layout\/save-load-reset-layout\"\n    extensions={[\"webm\", \"mp4\", \"ogg\"]}\n    widths={[256, 512, 720]}\n    annotation=\"_fsd50k_\"\n\/>\n\n## Build a layout with the Python API\n\nInstead of composing your layout in the UI and exporting it you can also build it with the Python API.\n\nMore information on the layout customization API can be found in the\n[layout API documentation](..\/..\/..\/api\/spotlight\/layout). You can also look at our\n[workflow examples](..\/..\/data-centric_ai\/playbook\/index.mdx) to browse through more complex examples.\n\nThis example illustrates the basic functionality:\n\n```python\nimport pandas as pd\nfrom renumics import spotlight\nfrom renumics.spotlight import layout\n\ndf = pd.read_csv(\"https:\/\/spotlight.renumics.com\/data\/fsd50k\/fsd50k-tiny.csv\")\nspotlight.show(\n    df,\n    dtype={\"audio\": spotlight.Audio, \"embedding\": spotlight.Embedding},\n    layout=layout.layout(\n        [\n            [layout.table()],\n            [\n                layout.similaritymap(\n                    columns=[\"embedding\"],\n                    color_by_column=\"annotation\",\n                    size_by_column=\"entropy\",\n                )\n            ],\n            [\n                layout.histogram(\n                    column=\"annotation\", stack_by_column=\"prediction_incorrect\"\n                )\n            ],\n        ],\n        layout.widgets.Inspector(),\n    ),\n)\n```"],"10":["---\ntitle: \ud83e\udd17 Loading Huggingface Data\nslug: \/docs\/loading-data\/huggingface\nsidebar_position: 30\n---\n\n# Loading Data from Huggingface datasets\n\n![Huggingface example](\/img\/speech_commands_vis_s.gif)\n\nThe Hugging Face datasets library not only provides access to more than 70k publicly available datasets, but also offers very convenient data preparation pipelines for custom datasets.\n\nRenumics Spotlight allows you to create interactive visualizations to identify critical clusters in your data. Because Spotlight understands the data semantics within Hugging Face datasets, you can get started with just one line of code:\n\n```python\nimport datasets\nfrom renumics import spotlight\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='validation')\n\nspotlight.show(ds)\n```\n\n## Spotlight \ud83e\udd1d Hugging Face datasets\n\nThe datasets library has several features that makes it an ideal tool for working with ML datasets: It stores tabular data (e.g. metadata, labels) along with unstructured data (e.g. images, audio) in a common Arrows table. Datasets also describes important data semantics through features (e.g. images, audio) and additional task-specific metadata.\n\nSpotlight directly works on top of the datasets library. This means that there is no need to copy or pre-process the dataset for data visualization and inspection. Spotlight loads the tabular data into memory to allow for efficient, client-side data analytics. Memory-intensive unstructured data samples (e.g. audio, images, video) are loaded lazily on demand. In most cases, data types and label mappings are inferred directly from the dataset. Here, we visualize the CIFAR-100 dataset with one line of code:\n\n```python\nds = datasets.load_dataset('cifar100', split='test')\nspotlight.show(ds)\n```\n\nIn cases where the data types are ambiguous or not specified, the Spotlight API allows to manually assign them:\n\n```python\nlabel_mapping = dict(zip(ds.features['fine_label'].names, range(len(ds.features['fine_label'].names))))\nspotlight.show(ds, dtype={'img': spotlight.Image, 'fine_label': spotlight.dtypes.CategoryDType(categories=label_mapping)})\n```\n\n## Supported data types\n\nMore details on the supported data types can be found in the [data types section](..\/loading-data#supported-data-types)\n\n## Detailed examples\n\nTake a look at our [use case section](..\/use-cases) to find more detailed examples for different modalities.","---\nslug: \/docs\/getting-started\nsidebar_position: 10\n---\n\nimport ReactPlayer from \"react-player\";\nimport Tabs from \"@theme\/Tabs\";\nimport TabItem from \"@theme\/TabItem\";\n\n# \ud83d\ude80 Getting Started\n\n> Spotlight helps you to **understand unstructured datasets** fast. You can create **interactive visualizations** from your dataframe with just a few lines of code. You can also leverage data enrichments (e.g. embeddings, prediction, uncertainties) to **identify critical clusters** in your data.\n\n![Dataframe example](\/img\/speech_commands_vis_s.gif)\n\n## What you'll need\n\n-   [Python](https:\/\/www.python.org\/downloads\/) version 3.8-3.11\n\n## Install Spotlight via [pip](https:\/\/packaging.python.org\/en\/latest\/key_projects\/#pip)\n\n```bash\npip install renumics-spotlight\n```\n\n> We recommend installing Spotlight and everything you need to work on your data in a separate [virtual environment](https:\/\/docs.python.org\/3\/tutorial\/venv.html)\n\n## Load your first dataset\n\nData can be loaded into Spotlight either from memory (as Python object) or from file. We currently support Pandas dataframes as well as Huggingface datasets and our own HDF5-based dataset format. Depending on the format, unstructured data samples are either stored directly in the dataframe or as a path to a separate file.\n\nThis is an example how your dataframe might look like:\n\n![Dataframe example](\/img\/dataframe_head_sample.png)\n\nYou can directly load your dataframe either via the Python API or the command line interface (CLI):\n\n<Tabs groupId=\"interface\">\n<TabItem value=\"python\" label=\"python\" default>\n\n```python\nimport pandas as pd\nfrom renumics import spotlight\n\ndf = pd.read_csv(\"https:\/\/renumics.com\/data\/mnist\/mnist-tiny.csv\")\nspotlight.show(df, dtype={\"image\": spotlight.Image, \"embedding\": spotlight.Embedding})\n```\n\n-   `pd.read_csv` loads a sample csv file as a pandas [DataFrame](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.html).\n-   `spotlight.show` opens up spotlight in the browser with the pandas dataframe ready for you to explore.\n-   The `dtype` argument specifies custom column types for the browser viewer.\n\n<\/TabItem>\n<TabItem value=\"bash\" label=\"CLI\">\n\n```bash\ncurl https:\/\/renumics.com\/data\/mnist\/mnist-tiny.csv -o mnist-tiny.csv\nspotlight mnist-tiny.csv --dtype image=Image --dtype embedding=Embedding\n```\n\n<\/TabItem>\n<\/Tabs>\n\n## Load a [Hugging Face](https:\/\/huggingface.co\/) dataset\n\nHuggingface datasets have a rich semantic description of the feature columns. Spotlight can thus parse data type descriptions and label mappings automatically. This means that creating a visualization is typically as simple as:\n\n```python\nimport datasets\nfrom renumics import spotlight\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='all')\n\nspotlight.show(ds)\n```\n\n## Exploring an enriched dataset with custom visualization layouts\n\nExploring raw unstructured datasets often yield little insights. Leveraging model results such as predictions or embeddings can help to uncover critical data samples and clusters. In practice, these enrichments can be stored in a separate dataframe and then joined with the raw dataset. Here is an example from the Huggingface hub:\n\n```python\nimport datasets\n\nds = datasets.load_dataset('speech_commands', 'v0.01', split='all')\nds_results = datasets.load_dataset('renumics\/speech_commands-ast-finetuned-results', 'v0.01', split='all')\nds = datasets.concatenate_datasets([ds, ds_results], axis=1)\n```\n\nDepending on the task at hand (e.g. EDA, model debugging, monitoring), you probably want to set up a suitable visualization layout. You can do so in the GUI and via API.","---\nsidebar_position: 20\nslug: \/docs\/loading-data\n---\n\n# Loading data\n\nWith Spotlight you can interactively explore your unstructured data directly from your dataframe. When the data is loaded into Spotlight, the tabular data (e.g. labels, metadata) is loaded into memory and you can use the web frontend to perform efficient in-memory analytics. Unstructured data samples (e.g. images, video, audio, time series) are loaded lazily from disk or web storage.\n\n## Supported data formats\n\nSpotlight can be started either through the Python API or via the Command Line Interface (CLI). Three different dataset representations are supported: [Pandas](https:\/\/pandas.pydata.org\/) dataframes, [Huggingface datasets](https:\/\/huggingface.co\/docs\/datasets\/index) and Spotlight datasets based on the HDF5-Format.\n\nIf you load your dataset via CLI, you can specify a file to be loaded. In this example we load a CSV file:\n\n```bash\nspotlight mnist-tiny.csv\n```\n\nWith the Python API you can additionally load in-memory datasets. This is useful when working in a notebook. Loading a Pandas dataframe is as simple as:\n\n```python\nfrom renumics import spotlight\n\nspotlight.show(df)\n```\n\nThis table gives an overview over the supported data formats:\n\n| Format                                      | CLI | Python API |\n| ------------------------------------------- | --- | ---------- |\n| CSV, Parquet, Feather, ORC (through Pandas) | \u2705  | \u2705         |\n| Pandas in memory                            | \u274c  | \u2705         |\n| Huggingface                                 | \u274c  | \u2705         |\n| Spotlight HDF5                              | \u2705  | \u2705         |\n\n## Supported data types\n\nSpotlight supports a wide range of data types both for tabular and unstructured data types. When possible, the data types are automatically discovered.\n\nIt is also possible to manually specify data types for certain columns:\n\n```python\nfrom renumics import spotlight\n\ndtype = {\"image\": spotlight.Image, \"embedding\":spotlight.Embedding}\nspotlight.show(df, dtype=dtype)\n```\n\nWe provide a more detailed description vor both [tabular data types](loading-data\/data-types#tabular-data-types) and [unstructured data types](loading-data\/data-types#unstructured-data-types).\n\n## Load a Pandas dataset\n\nFind [more information how to load your Pandas dataframe](loading-data\/pandas) in just a few lines of code.\n\n## Huggingface\n\nFind [more information how to load your Hugging Face dataset](loading-data\/huggingface) in just a few lines of code.\n\n## Spotlight HDF5 dataset\n\nFind more information how to use the [Spotlight HDF5 dataset format](loading-data\/hdf5) to load complex multimdal data."]}}